{"posts":[{"title":"[Notice] Docker Model Runner Installation","text":"📌 Introduction On Ubuntu 24.04 while installing the Docker Model Plugin, I encountered an issue where apt could not find the package. It turned out the Docker repository was pointing to the wrong release (pointing to focal instead of noble). ⭐ Note This article was initially drafted based on the real issue I encountered, with assistance from ChatGPT. I have verified the fix and revised the content to ensure it is accurate and clear for others facing a similar problem. 🚀 Quick Start 12345678910111213141516171819sudo apt-get updatesudo apt-get install docker-model-plugin -yHit:1 http://tw.archive.ubuntu.com/ubuntu noble InRelease Hit:2 http://tw.archive.ubuntu.com/ubuntu noble-updates InRelease Hit:3 http://tw.archive.ubuntu.com/ubuntu noble-backports InRelease Hit:4 https://packages.microsoft.com/repos/edge stable InRelease Hit:5 https://brave-browser-apt-release.s3.brave.com stable InRelease Hit:6 https://packages.microsoft.com/repos/code stable InRelease Hit:7 http://security.ubuntu.com/ubuntu noble-security InRelease Get:8 https://download.docker.com/linux/ubuntu focal InRelease [57.7 kB] Hit:9 https://ppa.launchpadcontent.net/mozillateam/ppa/ubuntu jammy InRelease Fetched 57.7 kB in 7s (8650 B/s)Reading package lists... DoneN: Skipping acquire of configured file 'main/binary-i386/Packages' as repository 'https://brave-browser-apt-release.s3.brave.com stable InRelease' doesn't support architecture 'i386'Reading package lists... DoneBuilding dependency tree... DoneReading state information... DoneE: Unable to locate package docker-model-plugin When I followed the tutorial How to Run Docker Model Runner on Ubuntu 24.04 I found that apt install could not find docker-model-plugin. The solution is 12345678910111213sudo apt-get updatesudo apt-get install \\ ca-certificates curl gnupg lsb-releasesudo mkdir -p /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\ | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho \\ &quot;deb [arch=$(dpkg --print-architecture) \\ signed-by=/etc/apt/keyrings/docker.gpg] \\ https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable&quot; \\ | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update 🔁 Key Takeaways The cause was that Docker’s APT repository pointed to the wrong release (focal instead of noble) Fixing this requires adding the correct Docker GPG key and configuring the proper repository for Ubuntu 24.04 After updating the APT sources, the docker-model-plugin package can be installed 🔗 References How to Run Docker Model Runner on Ubuntu 24.04","link":"/blog/note_docker_model_runner/"},{"title":"[note] ngrok - Free Static Domains","text":"📌 Introduction ngrok offers users free static domains! 🚀 Quick Start Install ngrok 1sudo snap install ngrok Create a domain Log in to ngrok and create your personal domain (random) Set up Token 1ngrok config add-authtoken $YOUR_AUTHTOKEN Create a tunnel 1ngrok http --url=$URL $PORT 🔗 References Free static domains for all ngrok users","link":"/blog/note_ngrok_free_static_domain/"},{"title":"[教學] 使用 AWS SAM 建立與執行 Lambda 函數","text":"📌 介紹 本指南介紹如何使用 AWS SAM 建立與執行 Lambda 函數，包含基本安裝、專案結構說明，以及在本機執行 Lambda 的流程。 🚀 快速開始 AWS CLI 1brew install awscli AWS SAM（Serverless Application Model）CLI 1brew install aws-sam-cli 初始化 SAM 專案 1sam init 專案結構總覽 1234567891011121314151617181920.├── __init__.py├── events│ └── event.json├── hello_world│ ├── __init__.py│ ├── app.py│ └── requirements.txt├── README.md├── samconfig.toml├── template.yaml└── tests ├── __init__.py ├── integration │ ├── __init__.py │ └── test_api_gateway.py ├── requirements.txt └── unit ├── __init__.py └── test_handler.py events/ - 包含用來測試 Lambda 函數的模擬事件有效載荷 JSON 檔案 hello_world/ - 應用程式所在；Lambda 相關函數（例如 handler，例如 app.py）與相依套件（例如 requirements.txt） tests/ - 單元測試資料夾 samconfig.toml - 儲存 SAM CLI 執行參數（例如部署區域、stack 名稱、S3 桶等），以便在執行 sam deploy 時簡化設定 template.yaml - 定義所有 Lambda 函數；主要的基礎設施即程式碼（IaC）檔案（哪些服務被使用以及它們的相依性）。它是 AWS CloudFormation 語法的擴充。 template.yaml 您可以使用 CloudFormation Linter 工具 cfn-lint 來偵測檔案中的格式與屬性錯誤 標頭 1234AWSTemplateFormatVersion: '2010-09-09'Transform: AWS::Serverless-2016-10-31Description: &gt; TODO.... AWSTemplateFormatVersion - AWS CloudFormation 的版本 Transform - 指示 CloudFormation 使用 SAM 擴充模板語法 Description - 專案描述 內容 Globals - 提供給資源的預設設定 Resources - 要建立的 AWS 資源。請參閱 AWS resource and property types reference 與 AWS SAM resources and properties Outputs - 部署後的預期輸出（您需要的資訊） samconfig.toml 參見 AWS SAM CLI configuration file、Configuring the AWS SAM CLI、AWS SAM CLI command reference 目的在於簡化使用 sam 指令時的複雜度 原本 使用 samconfig 後 sam build --cached --parallel --use-containers sam build sam local invoke --env-vars locals.json sam local invoke sam local start-api --env-vars locals.json --warm-containers EAGER sam local start-api 本機呼叫 1sam local invoke 1234567891011No current session found, using default AWS::AccountId Invoking app.lambda_handler (python3.13) Local image is up-to-date Using local image: public.ecr.aws/lambda/python:3.13-rapid-x86_64. Mounting /Users/XXXXXX/Documents/TEST/hello_world as /var/task:ro,delegated, inside runtime container START RequestId: f6a6ec50-58b2-432c-9381-ec45ca43b130 Version: $LATESTEND RequestId: e883464b-1216-43ae-b0fe-f7f803a73057REPORT RequestId: e883464b-1216-43ae-b0fe-f7f803a73057 Init Duration: 1.26 ms Duration: 381.91 ms Billed Duration: 382 ms Memory Size: 128 MB Max Memory Used: 128 MB{&quot;statusCode&quot;: 200, &quot;body&quot;: &quot;{\\&quot;message\\&quot;: \\&quot;hello world\\&quot;}&quot;} 🔁 重點回顧 安裝指令 了解 AWS SAM 專案結構 了解 template.yaml 與 samconfig.toml 這些檔案的用途及其相關官方文件 在本機呼叫一個簡單的「Hello World」Lambda 函數 🔗 參考資料 Day02-環境準備(一)安裝AWS CLI、Docker、AWS SAM CLI","link":"/blog/tutorial_chinese_aws_sam_install_and_lambda/"},{"title":"[Tutorial] Toy Example for Scanning Models","text":"📌 Introduction This article demonstrates how to use a simple example and the modelscan tool to detect unsafe PyTorch models. 🚀 Quick Start Before getting started you need to install the following packages 1pip install numpy torch modelscan Prepare a safe model 1234567891011121314151617from torch import nnimport torchclass SafeModel(nn.Module): def __init__(self): super(SafeModel, self).__init__() self.linear = nn.Linear(10, 1) def forward(self, x): return self.linear(x) if __name__ == &quot;__main__&quot;: model = SafeModel() # save the model torch.save(model.state_dict(), &quot;safe_model.pth&quot;) Prepare a malicious model This is a malicious model that produces output when you load it. 123456789101112131415from torch import nnimport torchimport osclass MaliciousModel: def __reduce__(self): print(&quot;Reduce called!&quot;) # Should print return (os.system, (&quot;echo 'This is a malicious model!' &gt; malicious_output.txt&quot;,)) if __name__ == &quot;__main__&quot;: model = MaliciousModel() # save the model torch.save(model, &quot;malicious_model.pth&quot;) Loading models Torch has basic protections, so we need to temporarily disable the weights_only option. After loading the model, you’ll see a file named malicious_output.txt. This indicates the malicious action occurred during loading. 1234567import torchsafe_model_path = &quot;safe_model.pth&quot;malicious_model_path = &quot;malicious_model.pth&quot;s_model = torch.load(safe_model_path)m_model = torch.load(malicious_model_path, weights_only=False) Using modelscan to scan models Safe model 1modelscan -p safe_model.pth 123456789Scanning /Users/hsiangjenli/Documents/github/mlops-survey/safe_model.pth:safe_model/data.pkl using modelscan.scanners.PickleUnsafeOpScan model scan--- Summary --- No issues found! 🎉--- Skipped --- Total skipped: 7 - run with --show-skipped to see the full list. Malicious model 1modelscan -p malicious_model.pth 12345678910111213141516171819202122232425Scanning /Users/hsiangjenli/Documents/github/mlops-survey/malicious_model.pth:malicious_model/data.pkl using modelscan.scanners.PickleUnsafeOpScan model scan--- Summary ---Total Issues: 1Total Issues By Severity: - LOW: 0 - MEDIUM: 0 - HIGH: 0 - CRITICAL: 1--- Issues by Severity ------ CRITICAL ---Unsafe operator found: - Severity: CRITICAL - Description: Use of unsafe operator 'system' from module 'posix' - Source: /Users/hsiangjenli/Documents/github/mlops-survey/malicious_model.pth:malicious_model/data.pkl--- Skipped --- Total skipped: 5 - run with --show-skipped to see the full list. 🔁 Review Created a safe model and a malicious model (which produces output when loaded) Scanned both models with modelscan 🔗 References https://github.com/protectai/modelscan","link":"/blog/tutorial_modelscan_toy_example/"},{"title":"[Reflection] First Experience with Codex","text":"📌 Introduction In short, Codex’s performance was far from ideal. 🚀 Quick Start Background - This repository is a refactor of my 30 days of daily notes. The goal is to make the structure clearer and more organized. Task 1 – This repository contains my daily notes. Your job is to read all the notes and assist in reorganizing them. Task 2 – Read all the notes and rewrite them using the same structure: Abstract, Content, Recap, and Reference. Also check for spelling errors and improve the content. Task 1 Results Maybe it’s my fault. Maybe my instructions weren’t clear enough. Codex created a README.md file containing a table of contents (TOC) like this. It looked fine, but I wanted it to read all the notes and help reorganize them, not just create a TOC. Task 2 Results I don’t know why, but Codex did follow my instructions to rewrite the notes… however, it almost removed all of the content, leaving only a very short abstract (1–2 lines). The quality of the rewritten content was also poor.","link":"/blog/reflection_codex/"},{"title":"[note] OCI Artifact?","text":"📌 What is an OCI Artifact? “OCI Artifact” stands for “Open Container Initiative Artifact.” It is a unified format that can be used to store anything — whether Docker images, Helm charts, WASM modules, machine learning models, SBOMs, policies, or scan reports. Most importantly, any item that follows the OCI format can be uploaded to or downloaded from registries (for example Harbor, DockerHub, Artifact Hub). 🚀 OCI Artifact Structure Tag – A human-readable name (for example nginx:1.0) that points to a manifest or index. A tag is a version label. Index – A list of manifests, commonly used for multi-platform artifacts. Manifest – Describes an artifact (e.g., Docker image, Helm chart) and references blobs. Blobs – The actual content, such as .tar.gz, binaries, or configuration files used by the artifact. 🔗 References OCI Image Layout Specification ORAS - Learn about OCI artifacts","link":"/blog/note_oci_artifact/"},{"title":"[note] Mac：不要安裝 Docker Desktop，改用 Colima — 常見問答","text":"📌 介紹 在 Mac 上，使用 Docker 並不必安裝官方的 Docker Desktop；可以使用像 Colima 這種更輕量的替代方案。不過，如果你先前安裝過 Docker Desktop，之後又透過 Homebrew 安裝 Docker CLI，卻沒有完全清除舊的設定，就可能會遇到一些錯誤。 🚀 操作 錯誤訊息 12# Error 1docker: Cannot connect to the Docker daemon at unix:///Users/XXXXXXXX/.docker/run/docker.sock. Is the docker daemon running? 12# Error 2docker: error getting credentials - err: exec: &quot;docker-credential-desktop&quot;: executable file not found in $PATH, out: `` 原因 因為最初使用 Docker Desktop 進行安裝，之後改用 Colima 並移除 Docker Desktop，導致部分原有的設定仍被使用，進而引發這些錯誤。 解決方法 Error 1 以 brew install docker 安裝的是 Docker CLI，而不是 Docker Engine。Docker Engine 必須在 Linux 系統上執行，而 macOS 並非 Linux，因此需要額外的 VM。Docker Desktop 會在背景啟動一個 VM，可能讓你沒有注意到；移除 Docker Desktop 後，就需要自行提供一個 VM 讓 Docker 運行。 安裝 colima 1brew install colima 啟動 colima 1colima start 照常使用 Docker 指令 Error 2 如果最初安裝過 Docker Desktop，有些設定可能被重複使用，導致出現此錯誤。 編輯 config.json 1nano ~/.docker/config.json 移除此段設定 123{ &quot;credsStore&quot;: &quot;desktop&quot;} 🔁 重點回顧 本篇摘要兩個常見錯誤： Docker 無法連接到 daemon 缺少 docker-credential-desktop，導致認證錯誤 🔗 參考資料 第 07 天：使用 KinD 為 Kubernetes 開發 - MacOS 使用 Colima 快速打造 Kubernetes 開發環境","link":"/blog/note_chinese_mac_docker_colima/"},{"title":"[chatgpt] 企業架構師、解決方案架構師與 DevOps 角色比較及轉型路徑","text":"📌 介紹 ⭐ 注意 本文由 ChatGPT 生成並經人工審核後發布，內容僅供參考。主要說明 DevOps、SA 與 EA 角色之間的關係，以及 DevOps 如何轉型為 SA 或 EA。 🧭 角色定位與差異概覽 Enterprise Architect (EA)：在企業層級定義長期 IT 策略與架構藍圖，確保技術解決方案與公司使命及業務目標一致 [1] [2] EA 類似 城市規劃師，繪製公司技術地景的整體藍圖 [3] 他們關注 大局 與 長期策略，制定標準與治理框架以指導技術決策。 Solution Architect (SA)：聚焦於特定產品或專案，評估業務需求並設計相應技術解決方案 [1:1] SA 扮演 橋樑，將業務需求與最終技術實作連接起來 [1:2] 他們像是為單一建築（單一系統）繪製藍圖的 建築師，在滿足專案需求的同時確保解決方案符合企業級架構標準 [3:1] SA 著重 具體細節 與 實務落地，帶領團隊將架構規劃轉為可交付系統。 DevOps Engineer：專注於軟體 交付流程與運維自動化，促進開發與運維協作以實現持續整合/交付（CI/CD）、自動化部署與系統監控，確保可靠且快速的軟體交付 [2:1] DevOps 強調 工具與流程最佳化，如同城市的 基礎建設維護者，建立道路與管線（部署流程）並維持交通暢通（穩定運行）。 共通點：三個角色都需要廣泛的技術知識與良好溝通協調能力，但 強調的面向不同。企業架構師強調策略與全域視野；解決方案架構師強調專案層級的技術設計與落實協調；DevOps 工程師強調工程執行與自動化效率。依企業規模與產業不同，這些角色是否設置以及職責劃分會有差異——系統越大越複雜，就越需要像 EA、SA 這樣明確分工的角色 [1:3]。 以下描述 EA、SA 與 DevOps 在新創與金融業情境下的職責、所需技能與常見技術差異，並提供從 DevOps 轉型為 SA 或 EA 的實務建議與學習資源。 🏗️ 企業架構師（EA） 職責與定位：企業架構師負責在組織中定義整體技術藍圖，並確保 IT 策略與公司業務策略一致 [1:4] 他們分析企業內外部需求，識別業務能力缺口，規劃未來技術路線圖 [1:5] EA 通常不會深入實作細節，而是制定標準並將具體實作任務委派給解決方案架構師或技術架構師 [1:6] EA 的一項重要任務是 架構治理：透過架構模型與原則引導專案遵循企業標準，避免孤島式發展。EA 經常與高階管理層協作，判斷哪些新興技術（例如 AI、區塊鏈）能帶來競爭優勢 [1:7] 核心技能：EA 需要 跨領域技術知識與商業洞察力。他們需精通企業架構框架（例如 TOGAF、Zachman）、理解業務流程與產業趨勢，並能將複雜技術概念與業務策略連結起來 [1:8] [1:9] EA 應具備卓越的 策略規劃與分析能力，利用 架構視圖與模型 分析 IT 版圖、找出營運瓶頸並規劃改進路徑 [1:10] EA 亦需強大的 溝通與影響力，能向高層解釋 IT 策略的價值並協調各部門達成共識 [1:11] 軟技能：EA 必須 有條理地工作 並 專注於架構治理，確保技術決策符合企業標準與法規。 常見技術與工具：由於 EA 看到的是整體，其技術重點偏向 架構建模與策略管理 工具而非特定程式語言。常見工具包括用於繪製架構藍圖、資產清單與路線圖的企業架構管理（EAM）工具，如 Archi、Sparx EA、LeanIX [1:12] EA 還應熟悉主要 雲端平台（AWS、Azure、GCP）與企業級解決方案（資料庫、ERP、Middleware）以便做出高階技術選擇。雖然 EA 不寫程式，但理解 技術標準與框架（如微服務架構、企業整合模式、安全框架）對評估解決方案可行性與相容性很重要。 新創 vs. 金融業情境差異：在 新創公司，因規模較小且多為單一產品，EA 角色可能由 CTO 承擔，架構較簡單且演進快速，強調敏捷多於嚴格治理。新創的 EA 可能 同時擔任 SA 與技術負責人，採取靈活方式。相對地，在 大型金融企業（銀行、保險），業務線複雜且法規要求高，通常會有專職的 EA 團隊。金融業 EA 常依循嚴謹框架（例如 TOGAF），建立 標準化的架構藍圖 與 治理流程，確保系統（舊有大型主機、資料倉儲、新應用）符合整體策略與規範。金融業 EA 須聚焦於 風險控管、資料隱私與合規，在引入新技術時格外謹慎。 🧱 解決方案架構師（SA） 職責與定位：解決方案架構師聚焦於 特定專案或產品 的架構設計。他們拿到企業架構師制定的原則與藍圖後，深入分析業務需求並設計可行的技術解決方案 [1:13] SA 的工作從 需求分析 開始：與產品經理及業務單位確認功能與品質要求（非功能需求），然後在多種技術選項中設計 架構解決方案（包含元件拆解、模組互動、資料流等）。在設計時，SA 必須在 企業級架構 與 實作細節 之間取得平衡 [1:14] 解決方案通過審核後，SA 常擔任 技術主導：帶領開發團隊理解架構、選擇技術並在開發期間確保架構被正確實作。SA 也會在實作過程中評估技術風險，確保交付系統符合初期的架構願景與需求 [1:15] 總結來說，SA 是專案中的技術領袖，確保「做對的解決方案」被「正確實作」。 核心技能：作為業務與技術之間的橋樑，SA 需要 廣度與深度兼具。SA 必須精通 系統設計原則 與 架構模式（分層架構、微服務、事件驅動、雲原生設計等），並為不同問題選擇合適的架構解法。SA 常由資深開發者升任，並在一兩個技術棧（如 Java/Spring、.NET 生態、或前後端領域）擁有深厚經驗，理解程式碼層級實務以設計可實現的方案。此外，SA 需具備強大的 溝通與協調能力，向開發團隊說明架構、與 EA 對齊一致性、並向非技術利害關係人說明技術如何解決業務問題。專案管理 技能也很重要，因為 SA 常擔任技術專案經理以維持利害關係人一致性 [1:16] 總之，SA 必須能 分析複雜問題並分解為可執行的解決方案，同時具備帶領團隊落實的 軟技能。 常見技術與工具：SA 的技術會依產業與專案而異，但通常涵蓋 廣泛的開發技術與架構工具。在雲端平台上，SA 應熟悉 AWS、Azure、GCP，並知道如何利用其服務（運算、儲存、資料庫、訊息佇列）構建可擴展系統 [2:2] 在應用架構上，SA 常使用 UML 或 C4 Model 繪製系統圖，並使用 Visio、draw.io、PlantUML 等工具設計。程式語言與框架則依領域而定：金融後端可能偏好 Java/Spring 或 .NET；新創可能採用 Python/Django、Node.js/Express、Go 等。SA 必須選擇合適的 資料庫（關聯式 SQL 或 NoSQL）、訊息中介（Kafka、RabbitMQ）等。除了應用開發，SA 還需理解 DevOps CI/CD 工具 原則——容器與 Kubernetes、CI 工具（Jenkins、GitLab CI）——以設計可部署且可運維的解決方案 [2:3] SA 也會考慮 效能與安全性，因此熟悉效能測試工具與安全最佳實務很有幫助。簡言之，SA 的技術知識覆蓋從白板構想到生產環境所需的一切。 新創 vs. 金融業情境差異：在 新創公司，SA 常兼任 技術團隊領導。因人力有限，SA 可能既設計架構又直接參與程式開發——角色較為實務導向。新創強調快速迭代，因此 SA 傾向使用 輕量框架與雲端服務 以加速開發並在上線後演進。在 金融企業，SA 通常是明確分工的角色，較少參與日常程式編寫，重心在 架構設計與協調。金融 SA 面臨許多 遺留系統整合 挑戰，需在支付系統、風控等業務領域提出合規的解法，並遵循企業架構標準。他們常使用 企業等級技術（如 IBM WebSphere、Oracle DB），並在設計上強調 安全性與交易一致性。金融 SA 與 EA 密切合作以確保合規，並與專案經理及外部廠商協調。簡言之，新創的 SA 更靈活多面；金融的 SA 更專業且需確保在嚴格環境下的可靠性。 🔧 DevOps 工程師（DevOps Engineer） 職責與定位：DevOps 工程師旨在打破 開發（Dev） 與 運維（Ops） 之間的障礙，建立高效且自動化的軟體交付流程。核心職責包括設計並實作 CI/CD 管線、自動化建置、測試與部署流程 [2:4]；使用 Terraform、CloudFormation 等撰寫基礎設施即程式碼（IaC）以部署與管理雲端基礎設施 [2:5]；配置並管理 持續監控 與 告警 系統（Prometheus、Grafana、CloudWatch）以確保系統穩定 [2:6]；推動 組態管理 與 自動化（Ansible、Chef）以降低人為錯誤。DevOps 工程師也負責 環境一致性，維持 dev/test/stage/prod 的環境相似性，幫助開發團隊快速交付與迭代。簡言之，DevOps 著重於軟體交付生命周期的效率與可靠性，是實現快速交付與持續改進文化的關鍵。 核心技能：DevOps 需具備廣泛的 工具鏈知識 與 協作能力。在技術面，他們需精通 CI/CD 工具（Jenkins、GitLab CI/CD）、版本控制（Git）、容器技術（Docker）與編排（Kubernetes）。因部署環境涉及 Linux 調校、服務設定、路由與防火牆設定，需對作業系統與網路有深入理解。DevOps 通常具備腳本/程式語言能力—Python、Shell、Go—用以撰寫自動化腳本或輔助工具。他們也必須了解 雲端架構與服務（AWS、Azure、GCP），因現代應用通常部署於雲端或混合環境。軟技能方面：DevOps 作為開發與 IT Ops 之間的膠合劑，需具備優秀的 溝通與協調 能力以推動 DevOps 文化。當事件發生時，DevOps 常協調故障排除並迅速聯絡相關利害關係人以解決問題 [4] 最後，他們應具備 持續學習 的心態，因為 DevOps 工具與實務快速演進—學習新技術（service mesh、GitOps）能提升團隊效率。 常見技術：DevOps 日常工作圍繞自動化與基礎設施技術。常見技術包括： 雲端與容器：AWS、Azure、GCP 及其服務（EC2、S3、RDS）、Linux 容器（Docker）與編排（Kubernetes、OpenShift）。DevOps 撰寫 Kubernetes YAML，使用 Helm Charts 管理容器化應用。 CI/CD 與組態管理：Jenkins、GitHub Actions、GitLab CI、CircleCI 用於持續整合/交付；Ansible、Chef、Puppet 用於組態管理與自動部署；Terraform、CloudFormation 用於 IaC 管理 [2:7] 這些工具結合能達成一鍵部署與基礎設施自動化。 監控與日誌：Prometheus、Grafana 用於指標監控；ELK/EFK（Elasticsearch + Kibana + Logstash/Fluentd）用於集中式日誌；雲原生監控（CloudWatch、Azure Monitor）。DevOps 設置告警與儀表板以即時監控系統健康。 版本控制與協作：Git 是基礎；理解 Git Flow 或 Pull Request 流程有助於團隊協作。Nexus/Artifactory 管理二進位件，Docker Registry 處理容器映像。 程式語言：雖然 DevOps 不專注業務邏輯開發，但會撰寫 腳本與工具。Shell 腳本用於系統任務，Python 常用於自動化；Go 越來越多用於 DevOps 工具（例如 Kubernetes CLI 工具）。DevOps 應能閱讀開發程式碼（Java、Python、JavaScript）以進行排錯。 新創 vs. 金融業情境差異：在 新創公司，DevOps 是早期團隊的關鍵成員，負責從零建立整個雲端基礎設施與 CI/CD 管線。新創採高度自動化、雲端優先的方式以加快部署（例如無伺服器架構）並降低維運。小團隊意味著 DevOps 常與開發與測試重疊，技能面更廣且更具靈活性。在 大型金融公司，DevOps 的導入可能受限於遺留流程與合規規定。許多金融機構透過試點團隊或專案逐步採用 DevOps。金融 DevOps 必須適應嚴格的變更管理與稽核要求，將審批與紀錄納入自動化流程。技術上，一些公司擁有私有資料中心，因此 DevOps 管理 混合雲（內部 + 私有 + 公有雲）並確保關鍵系統的高可用與災難復原。金融組織強調 存取控制與監控，DevOps 工具鏈必須符合安全政策（例如禁止敏感資料上傳至公有雲、CI/CD 管線需有變更審批）。總體而言，新創 DevOps 著重創新、速度與迭代；金融 DevOps 著重穩定性與合規，在速度與風險間取得平衡。 總結：依產業與規模不同，EA、SA 與 DevOps 的角色與劃分具彈性。在小型新創中，可能沒有正式的 EA 職稱或一人肩負多職；在大型金融公司，這三個角色明確且緊密合作。隨公司成長，架構治理變得更重要，從非正式的技術負責人設計演化為成立 SA 團隊，最終引入 EA 做策略監督 [3:2]。理解不同情境下的角色定位，有助於規劃適切的職涯發展與學習路徑。 🗺️ 從 DevOps 到架構師的轉型路徑 DevOps 工程師累積豐富的實務經驗與對交付流程的理解，這為成為架構師提供良好基礎 [4:1]。然而，從以工具與執行為導向的 DevOps 角色，轉向更高階的設計角色（Solution Architect 或 Enterprise Architect）需在 技術深度與廣度、商業理解與架構思維 上進一步成長。以下為逐步的學習與思維轉變指南： 技術與知識學習順序（基礎 → 進階 → 實作）： 基礎階段：強化 電腦科學與軟體工程基礎：資料結構、演算法、網路協定、作業系統等，為架構設計建立理論基礎。也要學習 軟體設計原則與物件導向概念（如 SOLID）以及基本設計模式。對 DevOps 來說，這能補足軟體設計的理論缺口。經典書籍（Clean Code、Design Patterns）與線上課程可鞏固這些基礎。 進階階段：深入研究 軟體架構理論與模式。學習常見架構風格（單體 vs 微服務、分散式系統原則、事件驅動、CQRS）、架構模式（分層架構、六邊形架構、Clean Architecture）與 架構決策的權衡。學習 企業架構框架（欲成為 EA 者，例如 TOGAF、BDAT）以理解治理方法。對於要成為 SA 的人，需在一兩個主流技術上具備深度專長以進行 系統設計—例如設計高併發網站或在金融交易系統中確保 ACID 屬性。在此階段，擴展 雲端與基礎設施知識：由於 DevOps 已熟悉 CI/CD 與容器，進一步學習 雲端架構設計（AWS Well-Architected Framework、混合雲）與 網路/安全架構（VPC 設計、零信任安全）[ ^devops_cloud_architect ] 也要涵蓋 資料庫基礎 與 大型分散式系統（NoSQL vs SQL 的取捨、CAP 定理、共識演算法如 Paxos/Raft），以便在成為架構師時做出前瞻的技術選擇。 實作階段：實務經驗不可或缺。開始 架構設計實作。一種做法是在工作中主動承接小型架構設計任務：重新設計某模組、優化部署拓撲，並與團隊討論你的設計以獲得回饋。參與 設計審查 流程以觀察資深架構師如何權衡利弊。如果工作上缺乏機會，可自行建立一兩個 架構專案：端對端設計一個短網址服務或電商系統（前端、後端、DB、快取、訊息），撰寫架構文件並為關鍵模組做 PoC。實作會揭示理論與現實間的落差並教會取捨。這些經驗在轉任架構師時非常重要。 補強商業理解與架構設計能力：架構師不僅是技術專家，更是理解業務的設計者。DevOps 背景需加強 領域知識 與 需求分析能力： 深化領域知識：無論產業為金融、電商等，學習業務流程與領域特性。對金融而言，理解核心銀行、支付清算與法規合規；對電商而言，理解訂單流程、庫存、SEO 等。透過向業務團隊提問、參加業務會議或閱讀產業報告來學習。有了商業洞察，才能設計真正符合業務需求的架構。 練習需求分析與架構設計：訓練自己從模糊的業務需求中萃取技術需求。嘗試撰寫 架構文件 或 技術提案：分析功能與非功能需求（效能、可擴展性、安全、合規），並提出涵蓋上下游關係、元件拆解、資料/控制流與關鍵技術選擇理由的架構解法。這能提升整體思考與決策能力。可與業界案例比對或諮詢資深架構師以反覆改進設計。 學習架構評估與決策技巧：架構師常做技術選型與權衡決策。透過學習 架構評估方法（例如 ATAM）、閱讀系統設計案例，了解他人如何在需求衝突下做抉擇。理解如何在高可用性 vs 一致性、延遲 vs 吞吐量、開發速度 vs 可維護性之間取得平衡。有了經驗，你會更有自信做出架構決策。 建議的實作專案類型與範圍以累積經驗：為了順利轉型，有意識地尋求能訓練架構能力的專案： 從小型架構設計開始：在團隊中志願承接 小專案或模組 的設計工作。作為 DevOps，你熟悉交付流程—嘗試延伸職責至設計，例如設計新的日誌收集架構、重構模組邊界或主導效能瓶頸優化。這些合宜範圍的任務能建立設計經驗與自信。 參與端到端解決方案：尋求參與超出交付之外的 端到端 專案生命周期。從需求討論、架構設計、開發到部署皆參與，觀察架構師如何與利害關係人互動並做出設計取捨。志願負責子系統架構。端到端參與能培養 整體觀，了解各階段如何影響架構。 加入架構審查或設計委員會：許多大型公司有架構審查委員會。即使僅作為旁聽者，也要加入這些討論，觀察各種架構提案與高階考量。若可能，提出問題與回饋，讓架構團隊注意到你的興趣與見解，進而帶來指導或機會。 擔任聯絡人 / 協調者：利用 DevOps 跨團隊位置，擔任 技術協調者。在跨職能專案中，協調前端、後端、DB 與運維的溝通以確保順利整合。這訓練你從更高層次看系統並協調多方利害關係人——是架構師日常工作的核心 [1:17] 在專案中扮演「初級架構師」角色，實際上就是開始執行部分架構師職責。 尋求導師與回饋：若公司有資深 SA 或 EA，主動請求指導並要求在專案中被帶領。提交架構提案後，邀請資深同事檢視並接受回饋。導師能加速你發現弱點並針對性地提升架構思維。 心態轉變建議（由工具導向轉為策略導向）：成為架構師不僅是技能升級，還是一次 心態的改變： 從執行者到設計者：DevOps 習慣動手解決問題；架構師必須 從更高層次觀察問題。從「我怎麼把這件事做得好」轉為「我們該做什麼以及為何這麼做」，專注於 做什麼 與 為何。培養 系統性思考，始終維持對整體系統的概念模型，考量決策的全域影響而非局部修補。 從工具導向到問題導向：DevOps 常以工具解決具體問題；架構師先聚焦 商業問題與優先順序。練習問：「此需求解決的是什麼商業問題？關鍵成功指標為何？」然後再推導合適的技術方案。避免過早陷入工具或框架選擇；先定義問題，再選工具。 從追新技術到重視穩健架構：DevOps 喜歡嘗試新工具；架構師更保守且理性，強調 技術選擇的長期影響。培養 技術節制力：評估成熟度、與現有環境的相容性及商業價值後再採用新技術。若新技術能解決關鍵問題才引入，否則避免增加複雜度。簡言之，從「技術本身」轉向「技術創造的價值」。 從局部優化到全域權衡：DevOps 常優化交付效率與單一系統可靠性；架構師必須做 全域權衡。對一個服務最佳的解法可能會提高生態系統複雜度或造成技術孤島。架構思維需要 在多面向（效能、成本、開發速度、可維護性、可擴展性）間衡量利弊。接受「沒有完美架構，只有適合當下需求的架構」的觀念，並據此設定優先順序。 提升溝通與領導力：從個人貢獻者轉為架構師意味著你要影響並領導他人。提升 溝通能力，能用簡單語言向非技術聽眾傳達複雜技術概念——這是 EA/SA 的核心能力 [5] 也要練習 聆聽與協商：架構提案需整合不同團隊利益——在堅守原則與彈性調整間取得平衡。建立被信任的 技術領導力 形象，讓團隊願意遵循你的決策。從帶領小型技術討論、分享學習開始，逐步累積影響力。 策略思維：欲晉升為 EA，需培養 策略性思維，關注市場與競爭以及公司層級的方向。思考：「未來 2–3 年業務可能如何變化？我們該做哪些技術準備？」EA 與高階主管共事以制定 IT 策略——因此需追蹤產業趨勢報告與競品的技術動向。學習以商業語言討論技術，將執行導向轉為將技術視為達成業務目標的 策略性資產。 上述步驟並非嚴格線性，可並行進行。例如在學理論時同時練習並發展軟技能。在此轉型中，DevOps 背景是優勢：你對交付流程的掌握帶來廣域視角與跨領域經驗，是架構師所需的特質 [4:2]。事實上，從 DevOps 到架構師是常見的職涯路徑——許多成功案例顯示，透過持續學習與擴大視野，你可以從 DevOps 工程師成長為傑出的解決方案架構師，甚至企業架構師 [4:3]。關鍵在於耐心與熱情：把每個專案當成磨練架構思維的機會；你的 DevOps 經驗將成為做出架構決策的獨特資產。 ⚡ 學習資源 轉型需要持續學習。下列資源涵蓋 GitHub 倉庫、線上課程、書籍與專業部落格/社群，提供深入知識與實務經驗： 💻 GitHub Solution Architect Learning Path: github.com 為 有志架構師 精選的學習資源彙整，涵蓋架構入門、基礎、雲端平台、架構模式、工具與認證——適合 DevOps 工程師系統性學習架構。 Awesome Software Architecture: github.com 社群維護的 軟體架構資源清單，彙整大量文章、影片與實作專案，涵蓋架構模式與原則——是快速掌握架構領域的良好入口。 System Design Primer: github.com 著名的 系統設計入門，介紹如何構建大型系統、常見系統設計面試題與許多實例（設計 Twitter、Facebook 等）。透過案例訓練架構設計思維十分適合。 Awesome DevOps: 一份經過整理的 DevOps 工具與實務清單。雖你可能已熟悉 DevOps，但此清單有助檢視與架構決策相關的領域，例如新基礎設施技術或 SRE 最佳實務（Awesome DevOps 文件列出雲端、組態管理、容器、監控等頂級解法：awesome-devops.xyz). 🎓 線上課程 Coursera: Software Design and Architecture Specialization: coursera.org 大學級別的系列課程，教導設計原則、模式與架構以建立可重用且可維護的系統架構。 Coursera: TOGAF Certification Course: coursera.org 聚焦核心企業架構概念（業務/資料/應用/技術 BDAT、ADM），對理解 EA 方法論有幫助。 Pluralsight: Developer to Architect: classcentral.com 為欲從開發/DevOps 轉型為架構師而設，涵蓋角色職責、所需技能，以及如何在專案生命週期中扮演架構師角色。 強調向技術與非技術利害關係人設計與溝通解決方案—作為轉型的路徑圖。 Udemy: Microservices Architecture &amp; Patterns: 可在 Udemy 等平台找到實務導向的微服務與雲原生設計課程。選擇高評價且由資深架構師授課的課程，以將理論應用於真實案例並深化理解。 📘 推薦書籍 Fundamentals of Software Architecture — Mark Richards &amp; Neal Ford。一本全面介紹架構模式、品質屬性權衡與架構師責任的著作，適合 DevOps 拓展架構視角。 Domain-Driven Design: Tackling Complexity in the Heart of Software — Eric Evans。架構師需將領域知識融入技術設計；此經典教你如何與領域專家協作並建模核心領域。 The Software Architect Elevator — Gregor Hohpe。聚焦架構師角色變化與在數位轉型中的軟技能——對進入大型企業的架構師有幫助；“電梯”隱喻幫助在策略與技術間穿梭。 Accelerate — Nicole Forsgren 等。基於研究的 DevOps 實務如何驅動業務價值。對於從 DevOps 轉為架構師的人，能強化技術與業務成果之間的連結，並在做架構決策時聚焦商業價值。書中對指標與組織變革的章節有助於推動架構或 DevOps 轉型。 Software Architecture in Practice — Len Bass 等。架構領域的經典教科書，涵蓋多面向並含多個案例分析—是系統性學習架構的基礎讀物。 另外，Martin Fowler 的著作如 Patterns of Enterprise Application Architecture 與其部落格也相當有價值。Fowler 對企業應用架構與重構的見解，有助於建立紮實的架構思維。 🌐 部落格與專業社群 Medium 技術刊物：Medium 上有許多架構與雲端文章。像 ITNext、Towards Data Science、The Startup 等刊物常發布架構相關內容。個別作者也分享從 DevOps 轉為架構師的經驗與雲端架構案例——這類敘事式文章提供實務指南。 Reddit 社群：訂閱相關子版： r/softwarearchitecture – 討論軟體架構、經驗分享、書籍推薦與架構挑戰。 r/DevOps – 專注 DevOps，但常觸及架構決策（CI/CD 設計、大型部署）。 r/cscareerquestions &amp; r/ExperiencedDevs – 職涯論壇，許多關於換角色情境的討論與資深從業者建議。 Stack Overflow / Stack Exchange：關注像 architecture 與 system-design 標籤以學習技術 Q&amp;A。Software Engineering Stack Exchange 有許多架構與設計決策的討論。參與可幫助解決技術問題並學習他人如何分析架構問題。 InfoQ 與 IBM Developer：InfoQ 有大量微服務、架構案例與企業架構治理文章（InfoQ 亦有中文內容）。IBM Developer 與 Microsoft Architecture Center 提供架構指南與參考架構。這些平台能追蹤產業趨勢，適合持續學習。 專業組織與論壇：加入架構論壇或在地社群。例如 The Open Group 的架構師社群（TOGAF 討論）、IEEE Software 群組。LinkedIn 上有「Software Architects」或「Enterprise Architecture Network」等群組，專業人士會分享文章與見解。積極參與有助建立人脈與知識。 在地社群與部落格：對繁體中文讀者，可關注台灣與香港的技術社群與部落格。例如 iT 邦幫忙 經常有架構與 DevOps 轉型的專欄，且在地的架構活動（如台灣 Architecture Summit）提供實務分享。 🔑 關鍵字 Enterprise Architecture Management Tools (EAM) The Open Group Architecture Framework (TOGAF) Zachman Framework Microservices Architecture Enterprise Integration Patterns (EIP) Security Framework System Component Decomposition System Design Principles Architectural Patterns Layered Architecture Event-Driven Architecture (EDA) Cloud-Native Design Lightweight Frameworks Binary Release Management Container Image Management Docker Registry SOLID Principles Design Patterns Monolithic Application Distributed System Principles Command Query Responsibility Segregation (CQRS) Hexagonal Architecture Clean Architecture Architectural Trade-offs Enterprise Architecture Domains (Business/Data/Application/Technology, BDAT) Architecture Governance Methodology Atomicity, Consistency, Isolation, Durability (ACID) Zero Trust Security Model Consensus Algorithms Paxos Algorithm Raft Algorithm Architecture Documentation Technical Proposal Functional Requirement Analysis Non-Functional Requirement Analysis Architecture Solution Design System Upstream and Downstream Relationships Data Flow and Control Flow Technology Selection Rationale Architecture Evaluation Methods Architecture Tradeoff Analysis Method (ATAM) Architecture-level Trade-offs (Availability, Consistency, Latency, Throughput, Developer Efficiency, Maintainability) Architecture Development Method (ADM) 🔖 參考資料 Enterprise Architect vs. Solution Architect vs. Technical Architect https://www.leanix.net/en/wiki/ea/enterprise-architect-vs-solution-architect-vs-technical-architect-whats-the-difference ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ Distinguishing Between DevOps Roles and AWS Solution Architects https://www.linkedin.com/pulse/distinguishing-between-devops-roles-aws-solution-architects-yagci-6jbqf/ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ ↩︎ Navigating the Architecture from Startup to Enterprise https://dilankam.medium.com/navigating-the-architecture-from-startup-to-enterprise-c355f6d3dd17 ↩︎ ↩︎ ↩︎ IT careers: 4 ways DevOps bolsters your architect skill set https://www.redhat.com/en/blog/devops-career-architecture ↩︎ ↩︎ ↩︎ ↩︎ How can I switch roles from DevOps to Architect? https://www.reddit.com/r/AWSCertifications/comments/1aorad5/how_can_i_switch_roles_from_devops_to_architect ↩︎","link":"/blog/chatgpt_devops_sa_ea/"},{"title":"[note] Resolve fstatat canonical snap directory: Permission denied","text":"📌 Introduction When using Snap applications on Ubuntu, you may encounter a confusing permission error related to fstatat. This note records a real issue, explores possible causes, and shares a simple, practical fix that worked. ⭐ Note This article was initially drafted with the help of ChatGPT based on a real issue I encountered. I have verified the solution and revised the content to ensure people facing a similar problem can understand it clearly and correctly. 📚 Prerequisites AppArmor LDAP (Lightweight Directory Access Protocol) fstatat snap Below are some key concepts mentioned in this post: Term Chinese description English description AppArmor Ubuntu’s security module used to restrict the resources an application can access, such as files and network. Ubuntu’s security module that restricts the resources applications can access. LDAP (Lightweight Directory Access Protocol) A common user authentication protocol used for centralized account management, typically in enterprise environments. A common user authentication protocol used for centralized account management, especially in enterprise environments. fstatat A Linux system call used to query file information. This error occurs because it failed. A Linux system call used to obtain file information. When this call fails, an error is produced. Snap Ubuntu’s packaging system that makes it easier to install, upgrade, and isolate applications. Ubuntu’s packaging system that makes it easier to install, update, and run applications in isolation. Non-standard home directory: The user’s home directory is located outside the default /home/username path, often on a different disk or mount point. Home directory is a symlink: The home directory appears under /home/username but is actually a symbolic link pointing to another location. 🧭 Troubleshooting framework Problem 1cannot fstatat canonical snap directory: Permission denied Root cause analysis In general, there are two common causes for this issue: The system is installed on an NTFS partition. The home directory is symlinked to a non-standard location. Check filesystem type 1234df -T /Filesystem Type 1K-blocks Used Available Use% Mounted on/dev/nvme0n1p4 ext4 669754920 44435324 591224492 7% / The system is installed on an ext4 partition Check symlinks 123456789ls -l /home/hsiangjenli/Documents/githubdrwxrwxr-x 10 hsiangjenli hsiangjenli 4096 一 27 17:05 blogdrwxrwxr-x 11 hsiangjenli hsiangjenli 4096 三 28 17:03 default-of-credit-card-clients-mlopsdrwxrwxr-x 8 hsiangjenli hsiangjenli 4096 一 29 16:40 hsiangjenli.github.iodrwxrwxr-x 5 hsiangjenli hsiangjenli 4096 三 27 14:28 java-from-pythondrwxrwxr-x 4 hsiangjenli hsiangjenli 4096 一 29 17:19 pic-beddrwxrwxr-x 11 hsiangjenli hsiangjenli 4096 二 16 08:44 python-package-templatedrwxrwxr-x 6 hsiangjenli hsiangjenli 4096 一 27 17:25 star-to-review These folders are not symlinks Why this happened I don’t know … Solution Surprisingly, running the following command resolved the issue: 1sudo dpkg-reconfigure apparmor Enter the target directory you want to use Restart the computer~~ 🔁 Key takeaways ✅ The error cannot fstatat canonical snap directory: Permission denied is often related to AppArmor restrictions ✅ Common causes include: The system or home directory using an NTFS partition The home directory being a symlink or located in a non-standard location 🔍 In this case: The system is on an ext4 partition — ✅ not NTFS. The home directory is not a symlink — ✅ not a symlink. ⚠️ The root cause remains unclear 🛠 The issue was resolved with the following steps: Run sudo dpkg-reconfigure apparmor During setup, enter the actual path of the home directory Reboot the system 🔗 References ‘Permission denied’ when running snap applications on Ubuntu 16.04 as a LDAP user Permission denied error when running apps installed as snap packages - Ubuntu 17.04","link":"/blog/note_snap_permission_denied/"},{"title":"[tutorial] Send Email with Mailgun + Python","text":"📌 Introduction This tutorial explains how to send emails using Mailgun and Python. You will learn how to set up Mailgun, generate an API key, and write Python code to send emails with or without attachments. 🚀 Quick Start Mailgun Mailgun offers a free plan, allowing up to 100 emails per day. Here are the three things you need to do Generate a Mailgun API key Note your Mailgun domain name (used for sending emails) Add your email to Mailgun (Mailgun only allows sending to authorized recipients) Create an API key Obtain your Mailgun domain Set up and verify your email Add your email to Mailgun Check your mailbox to complete verification Python To see the entire code : mailgun/demo.py 12345MAILGUN_API_KEY = os.getenv(&quot;MAILGUN_API_KEY&quot;)MAILGUN_DOMAIN_NAME = os.getenv(&quot;MAILGUN_DOMAIN_NAME&quot;)MAILGUN_API_URL = ( f&quot;https://api.mailgun.net/v3/{MAILGUN_DOMAIN_NAME}.mailgun.org/messages&quot;) 1234567891011@error_handler_for_send_emaildef send_email(from_email: str, to_email: Union[str, list], subject: str, text: str): # Define the email parameters email_data = {&quot;from&quot;: from_email, &quot;to&quot;: to_email, &quot;subject&quot;: subject, &quot;text&quot;: text} # Send the email r = requests.post( url=MAILGUN_API_URL, auth=(&quot;api&quot;, MAILGUN_API_KEY), data=email_data ) return r 1234567891011121314151617181920212223@error_handler_for_send_emaildef send_email_with_attachment( from_email: str, to_email: Union[str, list], subject: str, text: str, attachment_paths: list,): # Define the email parameters email_data = {&quot;from&quot;: from_email, &quot;to&quot;: to_email, &quot;subject&quot;: subject, &quot;text&quot;: text} # Read the attachment files = [ (&quot;attachment&quot;, open(attachment_path, &quot;rb&quot;)) for attachment_path in attachment_paths ] # Send the email r = requests.post( url=MAILGUN_API_URL, auth=(&quot;api&quot;, MAILGUN_API_KEY), data=email_data, files=files ) return r Gmail After sending mail from Mailgun, you can check the inbox. The message may be marked as spam; please check the spam folder for the email. 🔁 Key takeaways Mailgun setup: generate an API key, obtain your domain name, and verify your email Python integration: use the Mailgun API and Python to programmatically send emails Sending attachments: learn how to use the Mailgun API to send emails with attachments 🔗 References https://www.mailgun.com/blog/it-and-engineering/send-email-using-python/ https://stackoverflow.com/questions/53861582/sent-email-via-python-using-mailgun-api","link":"/blog/tutorial_mailgun_python/"},{"title":"[note] Strategic Thinking Model","text":"📌 Introduction “Open the mind, build thinking” 🚀 Mandala Nine-Grid 🚀 Flow: Eight Channels","link":"/blog/note_strategic_thinking_models/"},{"title":"[Tutorial] GitHub + PicGo + VSCode Extension","text":"📌 Introduction This article provides a tutorial for setting up GitHub, PicGo, and the VSCode extension to easily upload images to a GitHub repository. It explains the necessary prerequisites, the process to generate a GitHub token, and key points for configuring the PicGo extension in VSCode. 🚀 Quick Start Before you begin Make sure you have: A GitHub token with access to your repository A repository to store images GitHub Generating a GitHub token Go to Settings/Developer settings/Personal access tokens/Token (classic) Click Generate new token (classic) Set a recognizable name for the token and choose No expiration Select the scopes/permissions required for the token Configure the repository Set the repository to public to ensure your images can be accessed. VSCode Extension Install the PicGo extension in VSCode Set Pic Bed: Current to github Set Pic Bed &gt; Github: Repo to the public repository you created. Format: {username}/{repo_name} Set Pic Bed: Uploader to github Set Pic Bed &gt; Github: Branch to the branch of your public repository Configure Pic Bed &gt; Github: Path (optional). If you want images stored in a specific folder (e.g., images), make sure to include a trailing slash (/); otherwise the value will be treated as a prefix of the image name. Set Pic Bed &gt; Github: Token to the GitHub token you created earlier Troubleshooting If you see the following error, it means xclip is not installed on your system: 1PicGo: xclip not found! Please install xclip before run picgo. To fix this, install xclip using the following command: 1sudo apt install xclip 🔁 Key takeaways You need a GitHub token and a public repository to store images. Install the PicGo extension in VSCode to upload images. Link PicGo with GitHub by following the settings in the PicGo extension. A possible issue is ensuring xclip is installed on your system.","link":"/blog/tutorial_github_picgo_vscode/"},{"title":"[note] Windows 11 + Ubuntu 雙重開機安裝紀錄","text":"🎒 準備工作 💻 電腦資訊 型號: VivoBook 14 X1405VA-0041K 作業系統: Windows 11 處理器: i5-13500H SSD: NVMe SAMSUNG MZVL4512HBLU-00BTW BIOS 進入鍵: F2 開機裝置選擇鍵: F12 🎯 目標 目前 SSD 已安裝 Windows 11。目標是將 1 TB SSD 分割出分割區並安裝 Ubuntu 20.04 LTS。 - 350 GB - 650 GB 💻 步驟 🚨 注意 / 預防事項 根據線上教學，大多數更改是在 BIOS 選單中進行 但有些廠商會禁用這些選項（以防使用者誤傷電腦） 這會讓更改變得麻煩，並可能最終需要重置 Windows，所以請備份你的電腦 關閉 BitLocker 確保 BIOS 已更新到最新版本 最新的 BIOS 通常包含錯誤修正與較佳的硬體相容性，有助避免不必要的安裝問題 將 BIOS 開機模式設為 UEFI UEFI 是現代標準的開機模式，具有更佳的磁碟分割支援、更快的開機與安全性功能。Ubuntu 與 Windows 都建議使用 UEFI 而非傳統 BIOS（CSM）。 關閉 Secure Boot Secure Boot 會防止未經授權的作業系統開機，但某些 Ubuntu 版本或自訂驅動可能無法通過驗證，導致安裝失敗 在 BIOS 中找到 Secure Boot 設定並設為 Disabled（停用） 關閉 Fast Boot（BIOS 與 Windows 控制台） Fast Boot 會略過部分硬體初始化，可能導致 USB 安裝碟無法被偵測，影響 Ubuntu 安裝 在 BIOS 中找到 Fast Boot 並設為 Disabled 在 Windows 控制台的「硬體與音效 → 電源選項」中關閉 Fast Startup（快速啟動） 確保 SATA 設定為 AHCI 模式（這是最可能出問題的地方；某些 BIOS 可能不允許更改） 它不能是 RAID 關閉 CSM（相容性支援模組） CSM 提供傳統 BIOS 相容性；關閉它可讓系統專注於 UEFI 開機並降低潛在相容性問題 在 BIOS 中找到 CSM 並設為 Disabled 第一步：磁碟分割 先在 Windows 中分割磁碟以區分 Windows 與 Ubuntu 在電腦上搜尋 Create and format hard disk partitions 步驟 2 關閉快速啟動 Windows — 關閉 Fast Startup BIOS — 關閉 Fast Boot Windows 在 Windows 控制台中，找到電源管理選項並關閉快速啟動（Fast Startup） 步驟 3 移除與 Intel RST 相關的驅動程式 [1] 這個步驟可能會導致電腦無法啟動，需要重置整台系統（你要有心理準備 💔💔💔…） 但只有在重置之後你才能關閉 RST（將磁碟從 RAID 改為 AHCI）；否則 Ubuntu 在安裝時無法偵測到這顆 SSD 按 Win + X 開啟 裝置管理員 到 Storage Controllers，在那裡你會看到 Intel RST 驅動程式 這就是導致 Ubuntu 安裝時無法偵測 SSD 的禍首!!! 請依照 Ubuntu Documentation - RST &amp; Ubuntu installation 的步驟逐步解除安裝 Intel RST 驅動程式 按 Win + R，搜尋 regedit HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\iaStorV\\\\ 找到 Start 並將其值改為 0 找到 StartOverride 並將其值改為 0 HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Services\\\\storahci\\\\ 找到 Start 並將其值改為 0 找到 StartOverride 並將其值改為 0 解除安裝 Intel RST 驅動程式 完全解除安裝 Intel RST 驅動，然後重新啟動 在重新啟動期間你可能會看到藍屏顯示 INACCESSIBLE_BOOT_DEVICE；解法是重置整台電腦 重置後 再次按 Win + X，開啟裝置管理員並檢查 Storage Controllers，確認 Intel RST 是否仍在 步驟 4 安裝 Ubuntu 使用 USB 安裝 Ubuntu 按 F12 選擇 USB 隨身碟為開機裝置 由於分割區已預先建立，安裝類型選擇 → Something else（其他） 照著安裝程式繼續安裝；之後應該不會有重大問題 驅動程式問題 以往在桌機與較舊筆電安裝時，我沒有遇到 Wi‑Fi 驅動問題 但這台 VivoBook 出了問題；最快的解法是買一個相容 Linux 的 USB 無線網卡 TP-Link TL-WN725N22 術語表 CSM - 相容性支援模組 Intel RST - Intel 快速儲存技術 Ubuntu 文件 - RST 與 Ubuntu 安裝 https://help.ubuntu.com/rst/ ↩︎","link":"/blog/note_chinese_u2004_win11/"},{"title":"[Note] Want to install the latest version from a GitHub repository using pip","text":"📌 Introduction 🚀 Quick Start To install the development version from GitHub using pip, run the following command: 1pip install git+https://github.com/username/repository.git@devel 🔁 Summary You can use pip to install a specific branch from GitHub. The ‘devel’ branch typically contains unstable development versions. To install, use the command format: pip install git+{repo_url}@{branch_name}. Replace {repo_url} with your repository URL and {branch_name} with ‘devel’. Make sure pip is installed to use this command.","link":"/blog/note_pip_github_branch/"},{"title":"[Note] FISH?","text":"📌 Introduction This article introduces the FISH shell, a user-friendly interactive shell designed to improve the command line experience. It highlights its installation on MacOS and basic usage. 🚀 Quick Start Installing on MacOS 1brew install fish Using the FISH Shell Enter the FISH shell by typing fish 🔁 Key Takeaways FISH is a friendly interactive shell that enhances the command-line experience. On MacOS, you can install it via Homebrew using brew install fish. To start using FISH, just type fish in the terminal. 🔗 References How do I install, configure, and use Fish Shell in Linux? Finally, a command line shell for the 90s","link":"/blog/note_fish/"},{"title":"[note] MarkItDown: A tool for smoothly converting docx and pptx to markdown","text":"📌 Introduction This article discusses MarkItDown, a tool specifically designed to convert docx and pptx files into Markdown format with ease. The article introduces various Python packages used in this conversion workflow, enabling users to effectively handle documents and multimedia content. 🚀 Quick Start How MarkItDown works Below are the modules used by MarkItDown 12345678910111213141516dependencies = [ &quot;beautifulsoup4&quot;, &quot;requests&quot;, &quot;mammoth&quot;, &quot;markdownify&quot;, &quot;numpy&quot;, &quot;python-pptx&quot;, &quot;pandas&quot;, &quot;openpyxl&quot;, &quot;pdfminer.six&quot;, &quot;puremagic&quot;, &quot;pydub&quot;, &quot;youtube-transcript-api&quot;, &quot;SpeechRecognition&quot;, &quot;pathvalidate&quot;,] mammoth https://pypi.org/project/mammoth/ Mammoth is a tool for converting documents such as MS Word, Google Docs, and LibreOffice to HTML. python-pptx https://github.com/scanny/python-pptx A Python library for creating/reading/updating .pptx files openpyxl https://openpyxl.readthedocs.io/en/stable/ A Python library for reading/writing Excel 2010 xlsx, xlsm, xltx, xltm files pdfminer https://github.com/pdfminer/pdfminer.six Pdfminer.six is a community-maintained fork of the original PDFMiner. This module helps users extract information from PDF files. pydub https://github.com/jiaaro/pydub Lets you manipulate audio in an easy way youtube-transcript-api https://github.com/jdepoix/youtube-transcript-api A Python API to retrieve transcripts of specified YouTube videos. SpeechRecognition https://github.com/Uberi/speech_recognition/tree/master Supports speech-to-text engines such as Google Cloud Speech API, Wit.ai, Whisper, etc. markdownify https://github.com/matthewwithanm/python-markdownify Converts HTML to Markdown pathvalidate https://github.com/thombashi/pathvalidate A Python library for sanitizing and validating strings (such as filenames, file paths, etc.) puremagic https://github.com/cdgriffith/puremagic/tree/master Puremagic is a file type detection tool that can identify the type of an input file without relying on file extensions. Since extensions can be easily changed, relying on them alone to identify file types can be risky. The module defines a set of rules to read file contents and determine their type. 123456789101112131415# puremagic/magic_data.json{ &quot;extension_only&quot;: [ [&quot;&quot;, 0, &quot;.txt&quot;, &quot;text/plain&quot;, &quot;Text File&quot;], [&quot;&quot;, 0, &quot;.log&quot;, &quot;text/plain&quot;, &quot;Logger File&quot;], [&quot;&quot;, 0, &quot;.yaml&quot;, &quot;application/x-yaml&quot;, &quot;YAML File&quot;], [&quot;&quot;, 0, &quot;.yml&quot;, &quot;application/x-yaml&quot;, &quot;YAML File&quot;], [&quot;&quot;, 0, &quot;.toml&quot;, &quot;application/toml&quot;, &quot;TOML File&quot;], [&quot;&quot;, 0, &quot;.py&quot;, &quot;text/x-python&quot;, &quot;Python File&quot;], [&quot;&quot;, 0, &quot;.pyc&quot;, &quot;application/x-python&quot;, &quot;Python Complied File&quot;], [&quot;&quot;, 0, &quot;.pyd&quot;, &quot;application/x-python&quot;, &quot;Python Complied File&quot;], [&quot;&quot;, 0, &quot;.python_history&quot;, &quot;text/plain&quot;, &quot;Python History File&quot;], [&quot;&quot;, 0, &quot;.bat&quot;, &quot;application/x-script&quot;, &quot;Windows BAT file&quot;], [&quot;&quot;, 0, &quot;.gitconfig&quot;, &quot;text/plain&quot;, &quot;Git Ignore File&quot;],... 🔁 Key takeaways MarkItDown enables smooth conversion of docx and pptx files to Markdown format. This conversion requires various dependencies, including libraries for handling documents, audio, and data. Each mentioned library has a specific role, such as converting Word documents to HTML or reading Excel files. 🔗 References https://pypi.org/project/mammoth/ https://github.com/scanny/python-pptx https://openpyxl.readthedocs.io/en/stable/ https://github.com/pdfminer/pdfminer.six https://github.com/jiaaro/pydub https://github.com/jdepoix/youtube-transcript-api https://github.com/Uberi/speech_recognition/tree/master https://github.com/matthewwithanm/python-markdownify https://github.com/thombashi/pathvalidate https://github.com/cdgriffith/puremagic/tree/master","link":"/blog/note_markitdown/"},{"title":"[note] Fix Git installation issue in apache&#x2F;airflow:2.10.2 Docker image","text":"📌 Introduction 🚀 Quick Start 12345678FROM apache/airflow:slim-2.10.2USER rootRUN apt-get update &amp;&amp; apt-get install -y gitUSER airflowCOPY requirements.txt requirements.txtRUN pip install --no-cache-dir -r requirements.txt 🔁 Recap Permission errors may occur when installing packages from GitHub using the apache/airflow:2.10.2 image. To resolve this, install git as root before switching back to the airflow user. The provided Dockerfile demonstrates how to perform these steps.","link":"/blog/note_airflow_docker_permission_error/"},{"title":"[note] Using TypedDict to Improve Code Clarity","text":"📌 Introduction 🚀 Quick Start 12345678from typing import TypedDictimport datetimeclass News(TypedDict): title: str create_date: datetime.datetime content: str 🔁 Key Takeaways TypedDict helps maintain code clarity when using predefined fields. It improves developer efficiency by providing IDE suggestions. TypedDict has some limitations, especially regarding strict type checking. 🔗 References https://juejin.cn/post/7342790243009363977","link":"/blog/note_typedict/"},{"title":"[tutorial] Using commitollama to improve commit messages: VSCode and local LLM integration guide","text":"📌 Introduction This article introduces commitollama, a local-LLM-based alternative for generating commit messages, suitable for situations where project privacy must be protected. It explains the process of installing the commitollama extension in VSCode and the necessary setup before getting started. 🚀 Quick Start How to use Install the extension in VSCode. Install Ollama to integrate LLMs. Install Ollama Run the following command to install Ollama: 1curl -fsSL https://ollama.com/install.sh | sh After installation, you can run Ollama: 1ollama This will show a list of available commands: 12345678910111213141516171819202122Usage: ollama [flags] ollama [command]Available Commands: serve Start ollama create Create a model from a Modelfile show Show information for a model run Run a model pull Pull a model from a registry push Push a model to a registry list List models ps List running models cp Copy a model rm Remove a model help Help about any commandFlags: -h, --help help for ollama -v, --version Show version informationUse &quot;ollama [command] --help&quot; for more information about a command. Download the Phi3 model (3.8b) by running: 1ollama pull phi3:3.8b Start the Ollama service: 1ollama serve If you encounter the error Error: listen tcp 127.0.0.1:11434: bind: address already in use, you can find a solution here: https://github.com/ollama/ollama/issues/707. To restart Ollama, stop the current service and then restart: 12systemctl stop ollama.serviceollama serve To avoid models being deleted after download, see this discussion: https://github.com/ollama/ollama/issues/1493. Configuring in VSCode After installing the extension, you can use a custom model to generate commit messages. Press the button in the UI to automatically generate a commit message. 🔁 Summary commitollama is a privacy-focused alternative for generating commit messages, serving as a replacement for GitHub Copilot in this use case. The tool can use open-source LLMs like Llama, Mistral, and Phi3. It integrates easily into VSCode through a simple extension installation process. Users can obtain models, run the service, and effectively generate commit messages with minimal effort. 🔗 References https://github.com/ollama/ollama/issues/707 https://github.com/ollama/ollama/issues/1493","link":"/blog/tutorial_commitollama/"},{"title":"[Tutorial] Generate commit messages locally with Ollama and OpenCommit","text":"📌 Introduction This article explains how to combine Ollama and OpenCommit to generate commit messages locally. It includes an overview of running Ollama in a Docker container, instructions for using the Ollama CLI, and how to integrate Ollama with OpenCommit to generate commit messages. 🚀 Quick Start Start the container 1docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama-commit ollama/ollama:0.3.6 Enter the Docker container 1docker exec -it ollama-commit bash Pull the model 1ollama run gemma2:2b Start chatting 1&gt;&gt;&gt; Send a message (/? for help) Exit chat Type /bye to exit the chat. Install opencommit 1npm install -g opencommit Generate commit messages using local ollama server 1OCO_AI_PROVIDER='ollama/gemma2:2b' opencommit Output: 1234567891011121314151617181920212223242526┌ open-commit│◇ 1 staged files: README.md│◇ 📝 Commit message generated│└ Generated commit message:——————————————————feat(README.md): add link to Ollama website and examples of running models——————————————————│◇ Confirm the commit message?│ No│◇ Do you want to regenerate the message ?│ Yes│◇ 📝 Commit message generated│└ Generated commit message:——————————————————feat(README.md): add link to Ollama website and examples of model usage in README.md Error code 127 123456789101112Error: llama runner process has terminated: exit status 127&gt;&gt;&gt; [GIN] 2024/08/28 - 18:43:24 | 200 | 68.455µs | 127.0.0.1 | HEAD &quot;/&quot;&gt;&gt;&gt; [GIN] 2024/08/28 - 18:43:24 | 200 | 7.845273ms | 127.0.0.1 | POST &quot;/api/show&quot;&gt;&gt;&gt; time=2024-08-28T18:43:24.392Z level=INFO source=memory.go:309 msg=&quot;offload to cpu&quot; layers.requested=-1 layers.model=33 layers.offload=0 layers.split=&quot;&quot; memory.available=&quot;[7.3 GiB]&quot; memory.required.full=&quot;5.5 GiB&quot; memory.required.partial=&quot;0 B&quot; memory.required.kv=&quot;1.0 GiB&quot; memory.required.allocations=&quot;[5.5 GiB]&quot; memory.weights.total=&quot;4.7 GiB&quot; memory.weights.repeating=&quot;4.6 GiB&quot; memory.weights.nonrepeating=&quot;105.0 MiB&quot; memory.graph.full=&quot;560.0 MiB&quot; memory.graph.partial=&quot;585.0 MiB&quot;&gt;&gt;&gt; time=2024-08-28T18:43:24.392Z level=INFO source=server.go:391 msg=&quot;starting llama server&quot; cmd=&quot;/tmp/ollama731275887/runners/cpu/ollama_llama_server --model /root/.ollama/models/blobs/sha256-ff82381e2bea77d91c1b824c7afb83f6fb73e9f7de9dda631bcdbca564aa5435 --ctx-size 8192 --batch-size 512 --embedding --log-disable --no-mmap --parallel 4 --port 33357&quot;&gt;&gt;&gt; time=2024-08-28T18:43:24.392Z level=INFO source=sched.go:450 msg=&quot;loaded runners&quot; count=1&gt;&gt;&gt; time=2024-08-28T18:43:24.393Z level=INFO source=server.go:591 msg=&quot;waiting for llama runner to start responding&quot;&gt;&gt;&gt; time=2024-08-28T18:43:24.393Z level=INFO source=server.go:625 msg=&quot;waiting for server to become available&quot; status=&quot;llm server error&quot;&gt;&gt;&gt; /tmp/ollama731275887/runners/cpu/ollama_llama_server: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory&gt;&gt;&gt; time=2024-08-28T18:43:24.644Z level=ERROR source=sched.go:456 msg=&quot;error loading llama server&quot; error=&quot;llama runner process has terminated: exit status 127&quot;[GIN] 2024/08/28 - 18:43:24 | 500 | 266.021797ms | 127.0.0.1 | POST &quot;/api/chat&quot; This error occurs when the Docker image version is higher than 0.3.6. Therefore, you need to pull the ollama image version 0.3.6 and run the container. Click here to see the discussion. 🔁 Key takeaways Ollama allows using AI models to generate commit messages. This article details the steps to set up Ollama in a Docker environment. Integrating OpenCommit can simplify the process of using AI models to generate commit messages. Users can interact with the AI model via the chat interface. 🔗 References https://ollama.com/models https://github.com/ollama/ollama/issues/6541","link":"/blog/tutorial_ollama_opencommit/"},{"title":"[note] Install Golang (PATH)","text":"📌 Introduction 🚀 Quick Start Install Go using Homebrew: 1brew install go Verify the installation: 1ls ~/go/bin/ Temporarily update PATH: 1export PATH=$PATH:~/go/bin Permanently update PATH: 12echo 'export PATH=$PATH:~/go/bin' &gt;&gt; ~/.zshrcsource ~/.zshrc 🔁 Recap This guide explains how to install the Go programming language on macOS. Includes verification steps to check if the installation succeeded. Provides instructions for temporarily and permanently updating the PATH environment variable.","link":"/blog/note_go/"},{"title":"[tutorial] How to monitor CPU and memory usage in Python with psutil","text":"📌 Introduction This article introduces psutil, an open-source Python package that provides system information such as CPU, memory, disk, and network. It covers installing psutil, handy functions for monitoring CPU and memory usage, and how to use a decorator to integrate it into Python code. 🚀 Quick Start 1pip install psutil Useful functions in psutil CPU 1234psutil.cpu_count() # get the number of CPUpsutil.cpu_percent() # get the usage of all CPUpsutil.cpu_percent(percpu=True) # get the usage of per CPUpsutil.cpu_percent(interval=1) # get the usage of all CPU in 1 second, using interval will get more robust result Memory 1234567info = psutil.virtual_memory()# total memoryinfo.total / 1024 / 1024 / 1024 # bytes -&gt; GB# the usage of memoryinfo.percent MacOS 1# svmem(total=25769803776, available=7726628864, percent=70.0, used=9045114880, free=791134208, active=6949453824, inactive=6915768320, wired=2095661056) Ubuntu 12# will get more information like buffers, cached etc..# svmem(total=33541988352, available=25899790336, percent=22.8, used=7087771648, free=2703233024, active=15287881728, inactive=14264188928, buffers=965103616, cached=22785880064, shared=8265728, slab=904495104) How to integrate psutil into your program? We can use a decorator to monitor CPU and memory usage for each function. 1234567891011121314151617import psutildef monitor(func): def wrapper(*args, **kwargs): process = psutil.Process() cur_func_pid = process.pid process = psutil.Process(cur_func_pid) func(*args, **kwargs) cpu_usage = process.cpu_percent(interval=0.01) memory_usage = process.memory_info().rss / 1024 / 1024 / 1024 # bytes -&gt; GB print(f&quot;CPU usage: {cpu_usage}%&quot;) print(f&quot;Memory usage: {memory_usage}GB&quot;) return wrapper Example 12345678@monitordef example_code(): import numpy as np for i in range(100): np.random.rand(100, 100, 100)example_code() 🔁 Recap psutil is an open-source Python package for system monitoring. It provides handy functions to obtain CPU and memory usage information. You can easily monitor a Python function’s CPU and memory usage using a decorator. 🔗 References Python常用库之psutil使用指南 简单介绍psutil库（virtual_memory()、cpu_percent() 使用 psutil 模組進行 Python 系統監控與分析 Python 中的 Psutil 模組 Oracle Machine Learning for Python 的管理任務","link":"/blog/tutorial_psutil/"},{"title":"[tutorial] Create Your Own Python Package","text":"📌 Introduction Creating your own Python package helps maintain large projects because it organizes code that was previously scattered across directories. 🚀 Quick Start Create a setup.py file: 123from setuptools import setup, find_packagessetup(name=&quot;ntust_simslab&quot;, version=&quot;0.13&quot;, packages=find_packages()) Create a pyproject.toml file: 123456789101112131415[tool.poetry]name = &quot;ntust_simslab&quot;version = &quot;0.13&quot;description = &quot;A simple example for building a Python package.&quot;authors = [&quot;Hsiang-Jen Li &lt;hsiangjenli@gmail.com&gt;&quot;]readme = &quot;README.md&quot;packages = [{include = &quot;ntust_simslab&quot;}][tool.poetry.dependencies]python = &quot;^3.8&quot;requests = &quot;^2.28.2&quot;[build-system]requires = [&quot;poetry-core&quot;]build-backend = &quot;poetry.core.masonry.api&quot; Register a PyPI account at https://pypi.org/ to publish your package. 🔁 Recap Creating a Python package helps keep code organized in larger projects. Using setup.py is the traditional approach, while pyproject.toml is the modern approach when using Poetry. A PyPI account is required to publish packages. 🔗 References https://github.com/NTUST-SiMS-Lab/tutorial-simple-pypkg https://pypi.org/","link":"/blog/tutorial_pypi_pkg/"},{"title":"[note] Running Ubuntu VM on Mac with Multipass","text":"📌 Introduction Multipass is a simple tool provided by Canonical for easily running Ubuntu virtual machines. 🚀 Quick Start 1brew install qemu 123multipass launch 20.04 -c 8 -m 8G -d 100Gmultipass listmultipass shell your_vname 12sudo apt updatesudo apt install neofetch 1neofetch Install Desktop Environment 1sudo apt install ubuntu-desktop xrdp 🔁 Recap Learn how to quickly launch and manage Ubuntu VMs on macOS using Multipass Understand how to allocate resources and access the VM via shell 🔗 References canonical/multipass Multipass — 如 Docker 般的虛擬機 在 M1 或 M2 Mac 上使用 MULTI PASS 安裝並執行帶 GUI 的 Ubuntu 久違的在 Mac M2 上使用 Ubuntu","link":"/blog/note_multipass_ubuntu/"},{"title":"[note] Install GitHub Copilot CLI and Usage Guide","text":"📌 Introduction This article explains how to install and use the GitHub Copilot CLI. It includes the installation process using npm, setting the execution policy on Windows, and demonstrates how to use the CLI to get help for specific git commands. 🚀 Quick Start Install GitHub Copilot CLI:1npm install -g @githubnext/github-copilot-cli Set execution policy for PowerShell:1Set-ExecutionPolicy RemoteSigned -Scope CurrentUser Authenticate with GitHub Copilot CLI:1github-copilot-cli auth Test the CLI:1github-copilot-cli what-the-shell how to delete branch Output: ──────────────────── Command ──────────────────── git branch -d ────────────────── Explanation ────────────────── ○ git branch is used to list branches. ◆ -d will delete the branch . ✅ Run this command 📝 Modify query ❌ Cancel 🔁 Key Takeaways The GitHub Copilot CLI can be easily installed via npm. Windows users need to set the execution policy to allow running scripts. The CLI can assist with git commands and outputs the command along with explanations.","link":"/blog/note_installation_of_github_cli/"},{"title":"[note] Using Markmap to Efficiently Create Mind Maps: A Markdown-based VS Code Extension","text":"📌 Introduction This article explains how to use Visual Studio Code’s Markmap extension to convert Markdown syntax into mind maps, facilitating effective organization and visualization of ideas and information. 🚀 Quick Start Install this extension in VS Code 123456789101112131415161718192021# **My Education**## Vocational High School### KFHS### Applied Foreign Languages## Bachelor's### NKUST### Department of Money and Banking## Master's### NTUST### Department of Industrial Management#### Data Science#### Introduction to Blockchain and Its Applications#### Industrial IoT and Operational Technology Security#### AI Technologies and Business Applications#### Machine Learning#### Corporate Sustainability Management#### Production Management Preview 🔁 Key Takeaways Visualize Markdown documents as interactive mind maps using the Markmap extension. Easy installation; enables structured representation of content. The preview feature provides a visual presentation to enhance understanding.","link":"/blog/note_markmap/"},{"title":"[Tutorial] Installing Miniconda on Ubuntu","text":"📌 Introduction This article details the steps required to install Miniconda on Ubuntu, including downloading the installer and setting up the initial environment. 🚀 Quick Start 1sudo wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh 1sudo chmod +x Miniconda3-latest-Linux-x86_64.sh 1./Miniconda3-latest-Linux-x86_64.sh 12conda activateconda env list 🔁 Recap Miniconda is a minimal installer for conda, suitable for managing Python environments and packages. The installation process includes downloading the installer, making it executable, and running it to set up Miniconda. After installation, you can easily create and manage Python environments using conda commands. 🔗 References https://medium.com/featurepreneur/setting-up-miniconda-on-ubuntu-4bf6bece6f9b","link":"/blog/tutorial_ubuntu_miniconda/"},{"title":"[Notes] Using Gatsby","text":"📌 Introduction This article provides a guide on how to install Gatsby and create a new Gatsby site using starter themes. It covers installation steps, commands to create a Gatsby site, and links for troubleshooting common errors. 🚀 Quick Start Install Gatsby 12npm install -g gatsby-cligatsby --version gatsby-starter-blog 123gatsby new hjl https://github.com/gatsbyjs/gatsby-starter-blogcd hjlgatsby develop gatsby-starter-julia 12gatsby new RN https://github.com/niklasmtj/gatsby-starter-juliacd rn Using legacy peer dependencies 1--legacy-peer-deps 🔁 Recap Installing the Gatsby CLI with npm is very simple; you can use the command npm install -g gatsby-cli. After installation, you can check the installed Gatsby version. To create a new Gatsby site, you can use various starter themes, such as gatsby-starter-blog and gatsby-starter-julia. Common npm and Gatsby-related errors are detailed via multiple links provided in the article. 🔗 References Commands (Gatsby CLI) npm WARN old lockfile: the package-lock.json file was created with an old version of npm Error: command failed with exit code 1: npm install #27548 npm-upgrade","link":"/blog/note_gatsby/"}],"tags":[{"name":"devops","slug":"devops","link":"/blog/tags/devops/"},{"name":"sa","slug":"sa","link":"/blog/tags/sa/"},{"name":"ea","slug":"ea","link":"/blog/tags/ea/"},{"name":"docker","slug":"docker","link":"/blog/tags/docker/"},{"name":"ubuntu","slug":"ubuntu","link":"/blog/tags/ubuntu/"},{"name":"windows","slug":"windows","link":"/blog/tags/windows/"},{"name":"intel rst","slug":"intel-rst","link":"/blog/tags/intel-rst/"},{"name":"llm","slug":"llm","link":"/blog/tags/llm/"},{"name":"static-site","slug":"static-site","link":"/blog/tags/static-site/"},{"name":"gatsby","slug":"gatsby","link":"/blog/tags/gatsby/"},{"name":"linux","slug":"linux","link":"/blog/tags/linux/"},{"name":"go","slug":"go","link":"/blog/tags/go/"},{"name":"python","slug":"python","link":"/blog/tags/python/"},{"name":"markdown","slug":"markdown","link":"/blog/tags/markdown/"},{"name":"vs-code","slug":"vs-code","link":"/blog/tags/vs-code/"},{"name":"note","slug":"note","link":"/blog/tags/note/"},{"name":"ngrok","slug":"ngrok","link":"/blog/tags/ngrok/"},{"name":"git","slug":"git","link":"/blog/tags/git/"},{"name":"pip","slug":"pip","link":"/blog/tags/pip/"},{"name":"snap","slug":"snap","link":"/blog/tags/snap/"},{"name":"permission denied","slug":"permission-denied","link":"/blog/tags/permission-denied/"},{"name":"aws","slug":"aws","link":"/blog/tags/aws/"},{"name":"lambda","slug":"lambda","link":"/blog/tags/lambda/"},{"name":"ollama","slug":"ollama","link":"/blog/tags/ollama/"},{"name":"picgo","slug":"picgo","link":"/blog/tags/picgo/"},{"name":"mlsecops","slug":"mlsecops","link":"/blog/tags/mlsecops/"},{"name":"mailgun","slug":"mailgun","link":"/blog/tags/mailgun/"}],"categories":[],"pages":[{"title":"","text":"@import url('https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap'); @font-face { font-family: 'jf-openhuninn'; src: url('https://hsiangjenli.github.io/static/font/jf-openhuninn/jf-openhuninn.ttf'); } :root { --global-text-color: #4e4e4e; } body { font-family: \"Lato\", 'jf-openhuninn', \"Verdana\" !important; < HEAD ======= } .section { background-color: #e1e1e1 !important; >>>>>>> ab6907511f947861e6203c41a9f40d03cc1697aa } strong { color: var(--global-text-color) !important; font-weight: 700 !important; } em { color: var(--global-text-color) !important; } .title { font-weight: bolder !important; color: var(--global-text-color) !important; } .content h1, .content h2, .content h3, .content h4, .content h5, .content h6 { color: var(--global-text-color) !important; font-weight: bolder !important; } .content h1, .card-content h2 { padding-bottom: .75rem !important; border-bottom: 1px solid #e4e4e7 !important; } .card-content .article { color: var(--global-text-color) !important; } .navbar-item { color: var(--global-text-color) !important; font-weight: 700 !important; } .highlight-body { background-color: #eaeaea !important; }","link":"/blog/css/custom.css"}]}