{"type":"getPostsByTagId","data":[{"title":"[note] Introduction to automated AI security auditing framework petri","date":"2025-11-03T16:00:00.000Z","description":"<blockquote>\n<p>Note: This page is an AI-generated (gpt-5-mini-2025-08-07) translation from Traditional Chinese and may contain minor inaccuracies.</p>\n</blockquote>\n<h1>ğŸ“Œ Introduction</h1>\n<p>Petri is a red-team tool for AI safety testing that simulates realistic interactive scenarios to detect potential model risks. Through collaboration between the Auditor, Target, and Judge, it performs various tasks such as general audits, multi-model comparisons, and whistleblowing tests to check whether models leak information, exhibit bias, or show other issues, improving AI safety and reliability in complex scenarios.</p>","categories":[],"tags":[{"name":"llm","_id":"cmhwg0w8c000zmp3x0m5qaapc"},{"name":"security","_id":"cmhwg0w8e0014mp3x9al07cu2"}],"_path":"/note-ai-petri.en/","_link":"https://hsiangjenli.github.io/blog/note-ai-petri.en/","_id":"cmhwg0w7y0006mp3x1cab1d6c"},{"title":"[note] ä»‹ç´¹è‡ªå‹•åŒ– AI å®‰å…¨å¯©è¨ˆæ¡†æ¶ petri","date":"2025-11-03T16:00:00.000Z","description":"<h1>ğŸ“Œ ç°¡ä»‹</h1>\n<p>Petri æ˜¯ä¸€å€‹æ–¼ AI å®‰å…¨æ¸¬è©¦çš„ç´…éšŠå·¥å…·ï¼Œæ¨¡æ“¬çœŸå¯¦äº’å‹•æƒ…å¢ƒï¼Œæª¢æ¸¬æ¨¡å‹æ½›åœ¨é¢¨éšªã€‚é€éå¯©è¨ˆæ¨¡å‹ï¼ˆAuditorï¼‰ã€ç›®æ¨™æ¨¡å‹ï¼ˆTargetï¼‰èˆ‡è£åˆ¤æ¨¡å‹ï¼ˆJudgeï¼‰çš„å”ä½œï¼ŒåŸ·è¡Œå¤šç¨®ä»»å‹™ï¼Œä¾‹å¦‚é€šç”¨å¯©è¨ˆã€å¤šæ¨¡å‹æ¯”è¼ƒåŠå¹å“¨è€…æ¸¬è©¦ï¼Œæ¸¬è©¦æ¨¡å‹æ˜¯å¦æœ‰è³‡è¨Šæ´©æ¼æˆ–åè¦‹ç­‰å•é¡Œï¼Œæå‡ AI åœ¨è¤‡é›œå ´æ™¯ä¸­çš„å®‰å…¨æ€§èˆ‡å¯é æ€§</p>","categories":[],"tags":[{"name":"llm","_id":"cmhwg0w8c000zmp3x0m5qaapc"},{"name":"security","_id":"cmhwg0w8e0014mp3x9al07cu2"}],"_path":"/zh-TW/note-ai-petri/","_link":"https://hsiangjenli.github.io/blog/zh-TW/note-ai-petri/","_id":"cmhwg0w8t002bmp3xaog4dxm4"}]}