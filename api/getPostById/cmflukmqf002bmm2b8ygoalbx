{"type":"getPostById","data":{"title":"[教學] 掃描模型的簡單範例","date":"2025-06-13T16:00:00.000Z","description":"<blockquote>\n<p>註記：此頁為由 AI（gpt-5-mini-2025-08-07）自動翻譯自英文原文，可能含有少量不準確之處。</p>\n</blockquote>\n<h1>📌 介紹</h1>\n<p>本文示範如何使用一個簡單的範例與 <code>modelscan</code> 工具來偵測不安全的 PyTorch 模型。</p>","categories":[],"tags":[{"name":"mlsecops","_id":"cmflukmqu004bmm2bc0qec6dc"}],"content":"<blockquote>\n<p>註記：此頁為由 AI（gpt-5-mini-2025-08-07）自動翻譯自英文原文，可能含有少量不準確之處。</p>\n</blockquote>\n<h1>📌 介紹</h1>\n<p>本文示範如何使用一個簡單的範例與 <code>modelscan</code> 工具來偵測不安全的 PyTorch 模型。</p>\n<span id=\"more\"></span>\n<h1>🚀 快速開始</h1>\n<blockquote>\n<p>開始之前，您需要安裝以下套件</p>\n</blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install numpy torch modelscan</span><br></pre></td></tr></table></figure>\n<h2 id=\"準備安全模型\">準備安全模型</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SafeModel</span>(nn.Module):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(SafeModel, self).__init__()</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">10</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.linear(x)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    model = SafeModel()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># save the model</span></span><br><span class=\"line\">    torch.save(model.state_dict(), <span class=\"string\">&quot;safe_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"準備惡意模型\">準備惡意模型</h2>\n<p>這是一個在載入時會產生輸出的惡意模型。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MaliciousModel</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__reduce__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Reduce called!&quot;</span>)  <span class=\"comment\"># 應該會印出</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (os.system, (<span class=\"string\">&quot;echo &#x27;This is a malicious model!&#x27; &gt; malicious_output.txt&quot;</span>,))</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    model = MaliciousModel()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># save the model</span></span><br><span class=\"line\">    torch.save(model, <span class=\"string\">&quot;malicious_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"載入模型\">載入模型</h2>\n<p>Torch 已經有基本保護，因此我們需要暫時關閉 <code>weights_only</code> 選項。當你載入該模型後，你會看到名為 <code>malicious_output.txt</code> 的檔案。這表示惡意行為已經在載入時發生。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">safe_model_path = <span class=\"string\">&quot;safe_model.pth&quot;</span></span><br><span class=\"line\">malicious_model_path = <span class=\"string\">&quot;malicious_model.pth&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">s_model = torch.load(safe_model_path)</span><br><span class=\"line\">m_model = torch.load(malicious_model_path, weights_only=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"使用-modelscan-掃描模型\">使用 <code>modelscan</code> 掃描模型</h2>\n<h3 id=\"安全模型\">安全模型</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modelscan -p safe_model.pth</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">Scanning</span> /<span class=\"title class_\">Users</span>/hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/safe_model.<span class=\"property\">pth</span>:safe_model/data.<span class=\"property\">pkl</span> using modelscan.<span class=\"property\">scanners</span>.<span class=\"property\">PickleUnsafeOpScan</span> model scan</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Summary</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"title class_\">No</span> issues found! 🎉</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Skipped</span> --- </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"attr\">skipped</span>: <span class=\"number\">7</span> - run <span class=\"keyword\">with</span> --show-skipped to see the full list.</span><br></pre></td></tr></table></figure>\n<h3 id=\"惡意模型\">惡意模型</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modelscan -p malicious_model.pth</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">Scanning</span> /<span class=\"title class_\">Users</span>/hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/malicious_model.<span class=\"property\">pth</span>:malicious_model/data.<span class=\"property\">pkl</span> using modelscan.<span class=\"property\">scanners</span>.<span class=\"property\">PickleUnsafeOpScan</span> model scan</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Summary</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"title class_\">Issues</span>: <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"title class_\">Issues</span> <span class=\"title class_\">By</span> <span class=\"title class_\">Severity</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    - <span class=\"attr\">LOW</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">MEDIUM</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">HIGH</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">CRITICAL</span>: <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Issues</span> by <span class=\"title class_\">Severity</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"variable constant_\">CRITICAL</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Unsafe</span> operator <span class=\"attr\">found</span>:</span><br><span class=\"line\">  - <span class=\"title class_\">Severity</span>: <span class=\"variable constant_\">CRITICAL</span></span><br><span class=\"line\">  - <span class=\"title class_\">Description</span>: <span class=\"title class_\">Use</span> <span class=\"keyword\">of</span> unsafe operator <span class=\"string\">&#x27;system&#x27;</span> <span class=\"keyword\">from</span> <span class=\"variable language_\">module</span> <span class=\"string\">&#x27;posix&#x27;</span></span><br><span class=\"line\">  - <span class=\"title class_\">Source</span>: <span class=\"regexp\">/Users/</span>hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/malicious_model.<span class=\"property\">pth</span>:malicious_model/data.<span class=\"property\">pkl</span></span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Skipped</span> --- </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"attr\">skipped</span>: <span class=\"number\">5</span> - run <span class=\"keyword\">with</span> --show-skipped to see the full list.</span><br></pre></td></tr></table></figure>\n<h1>🔁 重點回顧</h1>\n<ol>\n<li>建立了一個安全模型與一個惡意模型（在載入時會產生輸出）</li>\n<li>使用 <code>modelscan</code> 掃描了兩個模型</li>\n</ol>\n<h1>🔗 參考資料</h1>\n<ul>\n<li><a href=\"https://github.com/protectai/modelscan\">https://github.com/protectai/modelscan</a></li>\n</ul>\n","_path":"tutorial-a-toy-example-of-scanning-models.zh-TW/","_link":"https://hsiangjenli.github.io/blog/tutorial-a-toy-example-of-scanning-models.zh-TW/","_id":"cmflukmqf002bmm2b8ygoalbx"}}