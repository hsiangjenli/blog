{"type":"getPostsByTag","data":[{"title":"[tutorial] Using commitollama to improve commit messages: VSCode and local LLM integration guide","date":"2024-09-03T16:00:00.000Z","description":"<h1>ðŸ“Œ Introduction</h1>\n<p>This article introduces commitollama, a local-LLM-based alternative for generating commit messages, suitable for situations where project privacy must be protected. It explains the process of installing the commitollama extension in VSCode and the necessary setup before getting started.</p>","categories":[],"tags":[{"name":"ollama","_id":"cmfj240x60029pw2b1s7h8jjy"}],"_path":"tutorial_commitollama/","_link":"https://hsiangjenli.github.io/blog/tutorial_commitollama/","_id":"cmfj240ww000zpw2b0sov4ti5"},{"title":"[Tutorial] Generate commit messages locally with Ollama and OpenCommit","date":"2024-08-28T16:00:00.000Z","description":"<h1>ðŸ“Œ Introduction</h1>\n<p>This article explains how to combine Ollama and OpenCommit to generate commit messages locally. It includes an overview of running Ollama in a Docker container, instructions for using the Ollama CLI, and how to integrate Ollama with OpenCommit to generate commit messages.</p>","categories":[],"tags":[{"name":"ollama","_id":"cmfj240x60029pw2b1s7h8jjy"}],"_path":"tutorial_ollama_opencommit/","_link":"https://hsiangjenli.github.io/blog/tutorial_ollama_opencommit/","_id":"cmfj240wz0018pw2bdxu113x6"}]}