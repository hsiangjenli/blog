{"type":"getPostsByTag","data":[{"title":"[tutorial] Enhancing Commit Messages with commitollama: A Guide for VSCode and Local LLM Integration","date":"2024-09-04T00:00:00.000Z","description":"<h1>ðŸ“Œ Introduction</h1>\n<p>This article introduces commitollama, an alternative to GitHub Copilot designed for generating commit messages using local LLMs, ensuring privacy for confidential projects. It outlines the installation process for the commitollama extension in VSCode and necessary setup steps to start using it effectively.</p>","categories":[],"tags":[{"name":"ollama","_id":"cmbwckhey001xl3q8daku9tgg"}],"_path":"tutorial_commitollama/","_link":"https://hsiangjenli.github.io/blog/tutorial_commitollama/","_id":"cmbwckheo000ul3q8e8yo2ob8"},{"title":"[tutorial] Using Ollama with OpenCommit for Local Commit Message Generation","date":"2024-08-29T00:00:00.000Z","description":"<h1>ðŸ“Œ Introduction</h1>\n<p>This article covers using Ollama with OpenCommit for generating commit messages locally. It includes an overview of running Ollama in a Docker container, instructions for using the Ollama CLI, and how to combine Ollama with OpenCommit for generating commit messages.</p>","categories":[],"tags":[{"name":"ollama","_id":"cmbwckhey001xl3q8daku9tgg"}],"_path":"tutorial_ollama_opencommit/","_link":"https://hsiangjenli.github.io/blog/tutorial_ollama_opencommit/","_id":"cmbwckher0011l3q88xny4xys"}]}