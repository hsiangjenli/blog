{"type":"getPostByPath","data":{"title":"[tutorial] A toy example of scanning models","date":"2025-06-13T16:00:00.000Z","description":"<h1>üìå Introduction</h1>\n<p>This article shows how to detect unsafe PyTorch models using a simple example and the <code>modelscan</code> tool.</p>","categories":[],"tags":[{"name":"mlsecops","_id":"cmfk4xmds0046mu2bd7g6aqqw"}],"content":"<h1>üìå Introduction</h1>\n<p>This article shows how to detect unsafe PyTorch models using a simple example and the <code>modelscan</code> tool.</p>\n<span id=\"more\"></span>\n<h1>üöÄ Quick Start</h1>\n<blockquote>\n<p>Before start you need to install following packages</p>\n</blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install numpy torch modelscan</span><br></pre></td></tr></table></figure>\n<h2 id=\"Prepare-Safe-Model\">Prepare Safe Model</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SafeModel</span>(nn.Module):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(SafeModel, self).__init__()</span><br><span class=\"line\">        self.linear = nn.Linear(<span class=\"number\">10</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.linear(x)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    model = SafeModel()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># save the model</span></span><br><span class=\"line\">    torch.save(model.state_dict(), <span class=\"string\">&quot;safe_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Prepare-Malicious-Model\">Prepare Malicious Model</h2>\n<p>This is a malicious model that will generate an output when you load it.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MaliciousModel</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__reduce__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Reduce called!&quot;</span>)  <span class=\"comment\"># ÊáâË©≤ÊúÉÂç∞Âá∫</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (os.system, (<span class=\"string\">&quot;echo &#x27;This is a malicious model!&#x27; &gt; malicious_output.txt&quot;</span>,))</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    model = MaliciousModel()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># save the model</span></span><br><span class=\"line\">    torch.save(model, <span class=\"string\">&quot;malicious_model.pth&quot;</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Load-model\">Load model</h2>\n<p>Torch already has basic protection, so we need to temporarily turn off the <code>weights_only</code> option. After you load the model, you will see a file called <code>malicious_output.txt</code>. This means the malicious behavior has already happened suddenly.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\">safe_model_path = <span class=\"string\">&quot;safe_model.pth&quot;</span></span><br><span class=\"line\">malicious_model_path = <span class=\"string\">&quot;malicious_model.pth&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">s_model = torch.load(safe_model_path)</span><br><span class=\"line\">m_model = torch.load(malicious_model_path, weights_only=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Using-modelscan-to-scan-the-model\">Using <code>modelscan</code> to scan the model</h2>\n<h3 id=\"Safe-Model\">Safe Model</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modelscan -p safe_model.pth</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">Scanning</span> /<span class=\"title class_\">Users</span>/hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/safe_model.<span class=\"property\">pth</span>:safe_model/data.<span class=\"property\">pkl</span> using modelscan.<span class=\"property\">scanners</span>.<span class=\"property\">PickleUnsafeOpScan</span> model scan</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Summary</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"title class_\">No</span> issues found! üéâ</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Skipped</span> --- </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"attr\">skipped</span>: <span class=\"number\">7</span> - run <span class=\"keyword\">with</span> --show-skipped to see the full list.</span><br></pre></td></tr></table></figure>\n<h3 id=\"Malicious-Model\">Malicious Model</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">modelscan -p malicious_model.pth</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"title class_\">Scanning</span> /<span class=\"title class_\">Users</span>/hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/malicious_model.<span class=\"property\">pth</span>:malicious_model/data.<span class=\"property\">pkl</span> using modelscan.<span class=\"property\">scanners</span>.<span class=\"property\">PickleUnsafeOpScan</span> model scan</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Summary</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"title class_\">Issues</span>: <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"title class_\">Issues</span> <span class=\"title class_\">By</span> <span class=\"title class_\">Severity</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    - <span class=\"attr\">LOW</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">MEDIUM</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">HIGH</span>: <span class=\"number\">0</span></span><br><span class=\"line\">    - <span class=\"attr\">CRITICAL</span>: <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Issues</span> by <span class=\"title class_\">Severity</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"variable constant_\">CRITICAL</span> ---</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Unsafe</span> operator <span class=\"attr\">found</span>:</span><br><span class=\"line\">  - <span class=\"title class_\">Severity</span>: <span class=\"variable constant_\">CRITICAL</span></span><br><span class=\"line\">  - <span class=\"title class_\">Description</span>: <span class=\"title class_\">Use</span> <span class=\"keyword\">of</span> unsafe operator <span class=\"string\">&#x27;system&#x27;</span> <span class=\"keyword\">from</span> <span class=\"variable language_\">module</span> <span class=\"string\">&#x27;posix&#x27;</span></span><br><span class=\"line\">  - <span class=\"title class_\">Source</span>: <span class=\"regexp\">/Users/</span>hsiangjenli/<span class=\"title class_\">Documents</span>/github/mlops-survey/malicious_model.<span class=\"property\">pth</span>:malicious_model/data.<span class=\"property\">pkl</span></span><br><span class=\"line\"></span><br><span class=\"line\">--- <span class=\"title class_\">Skipped</span> --- </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"title class_\">Total</span> <span class=\"attr\">skipped</span>: <span class=\"number\">5</span> - run <span class=\"keyword\">with</span> --show-skipped to see the full list.</span><br></pre></td></tr></table></figure>\n<h1>üîÅ Recap</h1>\n<ol>\n<li>Created a safe model and a malicious model (which generates output on load)</li>\n<li>Scanned both models using <code>modelscan</code></li>\n</ol>\n<h1>üîó References</h1>\n<ul>\n<li><a href=\"https://github.com/protectai/modelscan\">https://github.com/protectai/modelscan</a></li>\n</ul>\n","_path":"tutorial_modelscan_toy_example/","_link":"https://hsiangjenli.github.io/blog/tutorial_modelscan_toy_example/","_id":"cmfk4xmdk002xmu2b66fh8csm"}}