{"type":"getPostByPath","data":{"title":"[tutorial] Using commitollama to improve commit messages: VSCode and local LLM integration guide","date":"2024-09-03T16:00:00.000Z","description":"<blockquote>\n<p>Note: This page is an AI-generated (gpt-5-mini-2025-08-07) translation from Traditional Chinese and may contain minor inaccuracies.</p>\n<blockquote>\n<p>Note: This page was automatically translated from the original English by AI (gpt-5-mini-2025-08-07) and may contain minor inaccuracies.</p>\n</blockquote>\n<h1>üìå Introduction</h1>\n</blockquote>\n<p>This article introduces commitollama, a local-LLM-based alternative for generating commit messages, suitable for situations where project privacy must be protected. It explains the process of installing the commitollama extension in VSCode and the necessary setup before getting started.</p>","categories":[],"tags":[{"name":"ollama","_id":"cmfj10y56004cn42b708qbr4t"}],"content":"<blockquote>\n<p>Note: This page is an AI-generated (gpt-5-mini-2025-08-07) translation from Traditional Chinese and may contain minor inaccuracies.</p>\n<blockquote>\n<p>Note: This page was automatically translated from the original English by AI (gpt-5-mini-2025-08-07) and may contain minor inaccuracies.</p>\n</blockquote>\n<h1>üìå Introduction</h1>\n</blockquote>\n<p>This article introduces commitollama, a local-LLM-based alternative for generating commit messages, suitable for situations where project privacy must be protected. It explains the process of installing the commitollama extension in VSCode and the necessary setup before getting started.</p>\n<span id=\"more\"></span>\n<h1>üöÄ Quick Start</h1>\n<p><img src=\"https://commitollama.gallerycdn.vsassets.io/extensions/commitollama/commitollama/1.7.2/1723710671949/Microsoft.VisualStudio.Services.Icons.Default\" alt=\"\"></p>\n<h2 id=\"How-to-use\">How to use</h2>\n<ol>\n<li>Install the extension in VSCode.</li>\n<li>Install Ollama to integrate LLMs.</li>\n</ol>\n<p><img src=\"https://hackmd.io/_uploads/r1Vdxl8nR.png\" alt=\"Screenshot from 2024-09-04 22-35-57\"></p>\n<p><img src=\"https://hackmd.io/_uploads/Bk-6gx830.png\" alt=\"Screenshot from 2024-09-04 22-37-24\"></p>\n<h3 id=\"Install-Ollama\">Install Ollama</h3>\n<p>Run the following command to install Ollama:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://hackmd.io/_uploads/rJwuUxIn0.png\" alt=\"Screenshot from 2024-09-04 23-01-51\"></p>\n<p>After installation, you can run Ollama:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama</span><br></pre></td></tr></table></figure>\n<p>This will show a list of available commands:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Usage:</span><br><span class=\"line\">  ollama [flags]</span><br><span class=\"line\">  ollama [command]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  serve       Start ollama</span><br><span class=\"line\">  create      Create a model <span class=\"keyword\">from</span> a Modelfile</span><br><span class=\"line\">  show        Show information <span class=\"keyword\">for</span> a model</span><br><span class=\"line\">  run         Run a model</span><br><span class=\"line\">  pull        Pull a model <span class=\"keyword\">from</span> a registry</span><br><span class=\"line\">  push        Push a model to a registry</span><br><span class=\"line\">  <span class=\"built_in\">list</span>        <span class=\"type\">List</span> models</span><br><span class=\"line\">  ps          <span class=\"type\">List</span> running models</span><br><span class=\"line\">  cp          Copy a model</span><br><span class=\"line\">  rm          Remove a model</span><br><span class=\"line\">  <span class=\"built_in\">help</span>        Help about <span class=\"built_in\">any</span> command</span><br><span class=\"line\"></span><br><span class=\"line\">Flags:</span><br><span class=\"line\">  -h, --<span class=\"built_in\">help</span>      <span class=\"built_in\">help</span> <span class=\"keyword\">for</span> ollama</span><br><span class=\"line\">  -v, --version   Show version information</span><br><span class=\"line\"></span><br><span class=\"line\">Use <span class=\"string\">&quot;ollama [command] --help&quot;</span> <span class=\"keyword\">for</span> more information about a command.</span><br></pre></td></tr></table></figure>\n<!-- In this example, we will use `tavernari/git-commit-message` as the LLM model. That model is trained on Mistral0.3. -->\n<p>Download the Phi3 model (3.8b) by running:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama pull phi3:3.8b</span><br></pre></td></tr></table></figure>\n<p>Start the Ollama service:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama serve</span><br></pre></td></tr></table></figure>\n<!-- If you encounter the error `Error: listen tcp 127.0.0.1:11434: bind: address already in use`, refer to this discussion: https://github.com/ollama/ollama/issues/707. You may need to stop ollama and restart it. -->\n<p>If you encounter the error <code>Error: listen tcp 127.0.0.1:11434: bind: address already in use</code>, you can find a solution here: <a href=\"https://github.com/ollama/ollama/issues/707\">https://github.com/ollama/ollama/issues/707</a>.</p>\n<p>To restart Ollama, stop the current service and then restart:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop ollama.service</span><br><span class=\"line\">ollama serve</span><br></pre></td></tr></table></figure>\n<p>To avoid models being deleted after download, see this discussion: <a href=\"https://github.com/ollama/ollama/issues/1493\">https://github.com/ollama/ollama/issues/1493</a>.</p>\n<h3 id=\"Configuring-in-VSCode\">Configuring in VSCode</h3>\n<ul>\n<li>After installing the extension, you can use a custom model to generate commit messages.</li>\n<li>Press the button in the UI to automatically generate a commit message.</li>\n</ul>\n<p><img src=\"https://hackmd.io/_uploads/HklK2W82C.png\" alt=\"image\"></p>\n<h1>üîÅ Summary</h1>\n<ul>\n<li>commitollama is a privacy-focused alternative for generating commit messages, serving as a replacement for GitHub Copilot in this use case.</li>\n<li>The tool can use open-source LLMs like Llama, Mistral, and Phi3.</li>\n<li>It integrates easily into VSCode through a simple extension installation process.</li>\n<li>Users can obtain models, run the service, and effectively generate commit messages with minimal effort.</li>\n</ul>\n<h1>üîó References</h1>\n<ul>\n<li><a href=\"https://github.com/ollama/ollama/issues/707\">https://github.com/ollama/ollama/issues/707</a></li>\n<li><a href=\"https://github.com/ollama/ollama/issues/1493\">https://github.com/ollama/ollama/issues/1493</a></li>\n</ul>\n","_path":"tutorial_commitollama/","_link":"https://hsiangjenli.github.io/blog/tutorial_commitollama/","_id":"cmfj10y4w002sn42b6rk6h429"}}