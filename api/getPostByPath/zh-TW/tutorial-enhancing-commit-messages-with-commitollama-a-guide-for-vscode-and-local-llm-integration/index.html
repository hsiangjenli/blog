{"type":"getPostByPath","data":{"title":"[tutorial] ä½¿ç”¨ commitollama å¼·åŒ–æäº¤è¨Šæ¯ï¼šVSCode èˆ‡æœ¬åœ° LLM æ•´åˆæŒ‡å—","date":"2024-09-03T16:00:00.000Z","description":"<blockquote>\n<p>è¨»è¨˜ï¼šæ­¤é ç‚ºç”± AIï¼ˆgpt-5-mini-2025-08-07ï¼‰è‡ªå‹•ç¿»è­¯è‡ªè‹±æ–‡åŸæ–‡ï¼Œå¯èƒ½å«æœ‰å°‘é‡ä¸æº–ç¢ºä¹‹è™•ã€‚</p>\n</blockquote>\n<h1>ğŸ“Œ ä»‹ç´¹</h1>\n<p>æœ¬æ–‡ä»‹ç´¹ commitollamaï¼Œé€™æ˜¯ä¸€å€‹ç”¨æ–¼ç”¢ç”Ÿæäº¤è¨Šæ¯ï¼ˆcommit messagesï¼‰çš„å·¥å…·ï¼Œä½œç‚º GitHub Copilot çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ¡ç”¨æœ¬åœ° LLM ä»¥ç¢ºä¿æ©Ÿå¯†å°ˆæ¡ˆçš„éš±ç§ã€‚æœ¬æ–‡èªªæ˜åœ¨ VSCode ä¸­å®‰è£ commitollama æ“´å……å¥—ä»¶çš„æµç¨‹ä»¥åŠé–‹å§‹ä½¿ç”¨æ‰€éœ€çš„è¨­å®šæ­¥é©Ÿã€‚</p>","categories":[],"tags":[{"name":"ollama","_id":"cmllk3ymr0069rn3y3vgpda1r"}],"content":"\n    <style>\n    .post-lang-switch{\n      position: absolute;\n      top: .75rem;\n      right: .75rem;\n      z-index: 2;\n      color: var(--link, #3273dc);\n    }\n    .post-lang-switch:hover{opacity:.8}\n    </style>\n  \n    <a class=\"post-lang-switch\" href=\"/blog/tutorial-enhancing-commit-messages-with-commitollama-a-guide-for-vscode-and-local-llm-integration.en/\" title=\"View English version\" aria-label=\"View English version\">\n      <i class=\"fas fa-language\"></i>\n    </a>\n  <blockquote>\n<p>è¨»è¨˜ï¼šæ­¤é ç‚ºç”± AIï¼ˆgpt-5-mini-2025-08-07ï¼‰è‡ªå‹•ç¿»è­¯è‡ªè‹±æ–‡åŸæ–‡ï¼Œå¯èƒ½å«æœ‰å°‘é‡ä¸æº–ç¢ºä¹‹è™•ã€‚</p>\n</blockquote>\n<h1>ğŸ“Œ ä»‹ç´¹</h1>\n<p>æœ¬æ–‡ä»‹ç´¹ commitollamaï¼Œé€™æ˜¯ä¸€å€‹ç”¨æ–¼ç”¢ç”Ÿæäº¤è¨Šæ¯ï¼ˆcommit messagesï¼‰çš„å·¥å…·ï¼Œä½œç‚º GitHub Copilot çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ¡ç”¨æœ¬åœ° LLM ä»¥ç¢ºä¿æ©Ÿå¯†å°ˆæ¡ˆçš„éš±ç§ã€‚æœ¬æ–‡èªªæ˜åœ¨ VSCode ä¸­å®‰è£ commitollama æ“´å……å¥—ä»¶çš„æµç¨‹ä»¥åŠé–‹å§‹ä½¿ç”¨æ‰€éœ€çš„è¨­å®šæ­¥é©Ÿã€‚</p>\n<span id=\"more\"></span>\n<h1>ğŸš€ å¿«é€Ÿé–‹å§‹</h1>\n<p><img src=\"https://commitollama.gallerycdn.vsassets.io/extensions/commitollama/commitollama/1.7.2/1723710671949/Microsoft.VisualStudio.Services.Icons.Default\" alt=\"\"></p>\n<h2 id=\"ä½¿ç”¨æ–¹å¼\">ä½¿ç”¨æ–¹å¼</h2>\n<ol>\n<li>åœ¨ VSCode ä¸­å®‰è£è©²æ“´å……å¥—ä»¶ã€‚</li>\n<li>å®‰è£ Ollama ä»¥æ•´åˆ LLMã€‚</li>\n</ol>\n<p><img src=\"https://hackmd.io/_uploads/r1Vdxl8nR.png\" alt=\"æˆªåœ–ï¼š2024-09-04 22-35-57\"></p>\n<p><img src=\"https://hackmd.io/_uploads/Bk-6gx830.png\" alt=\"æˆªåœ–ï¼š2024-09-04 22-37-24\"></p>\n<h3 id=\"å®‰è£-Ollama\">å®‰è£ Ollama</h3>\n<p>åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ä»¥å®‰è£ Ollamaï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://hackmd.io/_uploads/rJwuUxIn0.png\" alt=\"æˆªåœ–ï¼š2024-09-04 23-01-51\"></p>\n<p>å®‰è£å®Œæˆå¾Œï¼Œå¯é€éä¸‹åˆ—æ–¹å¼åŸ·è¡Œ Ollamaï¼š</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama</span><br></pre></td></tr></table></figure>\n<p>é€™æœƒé¡¯ç¤ºå¯ç”¨æŒ‡ä»¤æ¸…å–®ï¼š</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Usage:</span><br><span class=\"line\">  ollama [flags]</span><br><span class=\"line\">  ollama [command]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  serve       Start ollama</span><br><span class=\"line\">  create      Create a model <span class=\"keyword\">from</span> a Modelfile</span><br><span class=\"line\">  show        Show information <span class=\"keyword\">for</span> a model</span><br><span class=\"line\">  run         Run a model</span><br><span class=\"line\">  pull        Pull a model <span class=\"keyword\">from</span> a registry</span><br><span class=\"line\">  push        Push a model to a registry</span><br><span class=\"line\">  <span class=\"built_in\">list</span>        <span class=\"type\">List</span> models</span><br><span class=\"line\">  ps          <span class=\"type\">List</span> running models</span><br><span class=\"line\">  cp          Copy a model</span><br><span class=\"line\">  rm          Remove a model</span><br><span class=\"line\">  <span class=\"built_in\">help</span>        Help about <span class=\"built_in\">any</span> command</span><br><span class=\"line\"></span><br><span class=\"line\">Flags:</span><br><span class=\"line\">  -h, --<span class=\"built_in\">help</span>      <span class=\"built_in\">help</span> <span class=\"keyword\">for</span> ollama</span><br><span class=\"line\">  -v, --version   Show version information</span><br><span class=\"line\"></span><br><span class=\"line\">Use <span class=\"string\">&quot;ollama [command] --help&quot;</span> <span class=\"keyword\">for</span> more information about a command.</span><br></pre></td></tr></table></figure>\n<!-- In this case, we will use `tavernari/git-commit-message` as our LLM model. This model is trained on Mistral0.3 . -->\n<p>ä¸‹è¼‰ Phi3 æ¨¡å‹ (3.8b)ï¼ŒåŸ·è¡Œï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama pull phi3:3.8b</span><br></pre></td></tr></table></figure>\n<p>å•Ÿå‹• Ollama æœå‹™ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ollama serve</span><br></pre></td></tr></table></figure>\n<!-- If there a error message `Error: listen tcp 127.0.0.1:11434: bind: address already in use`. Which can be found at [there](https://github.com/ollama/ollama/issues/707) . You need to shutdown the ollama and restart it. -->\n<p>å¦‚æœé‡åˆ°éŒ¯èª¤è¨Šæ¯ <code>Error: listen tcp 127.0.0.1:11434: bind: address already in use</code>ï¼Œå¯åœ¨ <a href=\"https://github.com/ollama/ollama/issues/707\">é€™è£¡</a> æ‰¾åˆ°è§£æ³•ã€‚</p>\n<p>è¦é‡æ–°å•Ÿå‹• Ollamaï¼Œå…ˆåœæ­¢ç›®å‰æœå‹™å†é‡æ–°å•Ÿå‹•ï¼š</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop ollama.service</span><br><span class=\"line\">ollama serve</span><br></pre></td></tr></table></figure>\n<p>è‹¥è¦é¿å…ä¸‹è¼‰å¾Œæ¨¡å‹è¢«åˆªé™¤ï¼Œè«‹åƒé–±æ­¤è¨è«– <a href=\"https://github.com/ollama/ollama/issues/1493\">é€™è£¡</a> ã€‚</p>\n<h3 id=\"åœ¨-VSCode-ä¸­è¨­å®š\">åœ¨ VSCode ä¸­è¨­å®š</h3>\n<ul>\n<li>å®‰è£æ“´å……å¥—ä»¶å¾Œï¼Œå¯ä½¿ç”¨è‡ªè¨‚æ¨¡å‹ä¾†ç”¢ç”Ÿæäº¤è¨Šæ¯ã€‚</li>\n<li>åœ¨ä»‹é¢ä¸­æŒ‰ä¸‹æŒ‰éˆ•å³å¯è‡ªå‹•ç”¢ç”Ÿæäº¤è¨Šæ¯ã€‚</li>\n</ul>\n<p><img src=\"https://hackmd.io/_uploads/HklK2W82C.png\" alt=\"åœ–ç‰‡\"></p>\n<h1>ğŸ” å›é¡§</h1>\n<ul>\n<li>commitollama æ˜¯ä¸€å€‹é‡è¦–éš±ç§çš„æäº¤è¨Šæ¯ç”¢ç”Ÿå™¨ï¼Œä½œç‚º GitHub Copilot çš„æ›¿ä»£æ–¹æ¡ˆã€‚</li>\n<li>è©²å·¥å…·åˆ©ç”¨é–‹æ”¾åŸå§‹ç¢¼ LLMï¼Œä¾‹å¦‚ Llamaã€Mistral èˆ‡ Phi3ã€‚</li>\n<li>é€éç°¡å–®çš„æ“´å……å¥—ä»¶å®‰è£ç¨‹åºå³å¯èˆ‡ VSCode è¼•é¬†æ•´åˆã€‚</li>\n<li>ä½¿ç”¨è€…å¯ä»¥è¼•é¬†å–å¾—æ¨¡å‹ã€å•Ÿå‹•æœå‹™ä¸¦æœ‰æ•ˆç‡åœ°ç”Ÿæˆæäº¤è¨Šæ¯ã€‚</li>\n</ul>\n<h1>ğŸ”— åƒè€ƒè³‡æ–™</h1>\n<ul>\n<li><a href=\"https://github.com/ollama/ollama/issues/707\">https://github.com/ollama/ollama/issues/707</a></li>\n<li><a href=\"https://github.com/ollama/ollama/issues/1493\">https://github.com/ollama/ollama/issues/1493</a></li>\n</ul>\n","_path":"/zh-TW/tutorial-enhancing-commit-messages-with-commitollama-a-guide-for-vscode-and-local-llm-integration/","_link":"https://hsiangjenli.github.io/blog/zh-TW/tutorial-enhancing-commit-messages-with-commitollama-a-guide-for-vscode-and-local-llm-integration/","_id":"cmllk3ym80035rn3y6k72bmbc"}}